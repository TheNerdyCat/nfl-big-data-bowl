{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Big Data Bowl - Feature Engineering v1\n",
    "-------------------\n",
    "TheNerdyCat <br>\n",
    "27 Nov 2019 Deadline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "import kaggle\n",
    "import math\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "#import optuna\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [15,10]\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/nfl-big-data-bowl-2020/train.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):#\n",
    "    \n",
    "    def clean_position(pos):\n",
    "        if pos == 'SAF':\n",
    "            return 'DB'\n",
    "        if pos == 'S':\n",
    "            return 'DB'\n",
    "        elif pos == 'OG':\n",
    "            return 'G'\n",
    "        elif pos == \"OT\":\n",
    "            return 'T'\n",
    "        else:\n",
    "            return pos\n",
    "    \n",
    "    def clean_offenceformation(of):\n",
    "        if of == \"SHOTGUN\":\n",
    "            return 9\n",
    "        elif of == \"SINGLEBACK\":\n",
    "            return 8\n",
    "        elif of == \"JUMBO\":\n",
    "            return 6\n",
    "        elif of == \"PISTOL\":\n",
    "            return 5\n",
    "        elif of == \"I_FORM\":\n",
    "            return 4\n",
    "        elif of == \"ACE\":\n",
    "            return 3\n",
    "        elif of ==  \"WILDCAT\":\n",
    "            return 2\n",
    "        elif of == \"EMPTY\":\n",
    "            return 1\n",
    "        else: \n",
    "            return 7\n",
    "    \n",
    "    def create_generalposition(pos):\n",
    "        if pos == 'SS' or pos == 'FS' or pos == 'CB' or pos == 'DB':\n",
    "            return 'DB'\n",
    "        elif pos == 'DE' or pos == 'DT' or pos == 'DL':\n",
    "            return 'DL'\n",
    "        elif pos == 'ILB' or pos == 'OLB' or pos == 'MLB' or pos == 'LB':\n",
    "            return 'LB'\n",
    "        elif pos == 'WR':\n",
    "            return 'WR'\n",
    "        elif pos == 'TE':\n",
    "            return 'TE'\n",
    "        elif pos == 'T' or pos == 'G' or pos == 'C' or pos == 'NT' or pos == 'OL':\n",
    "            return 'OL'\n",
    "        elif pos == 'QB' or pos == 'RB' or pos == 'FB' or pos == 'HB' or pos == 'TB' or pos == 'WB':\n",
    "            return 'OB'\n",
    "        else:\n",
    "            return 'Other'\n",
    "\n",
    "    def utc2sec(x):\n",
    "        return int(x.split(\"-\")[2].split(\":\")[2].split(\".\")[0])\n",
    "    \n",
    "    def timesnap2date(x):\n",
    "        day = x.split(\"T\")[0]\n",
    "        return day\n",
    "    \n",
    "    def timesnap2day(x):\n",
    "        days = x.split(\"-\")\n",
    "        return 365 * int(days[0]) + 30 * int(days[1]) + int(days[2][:2])\n",
    "        \n",
    "    def gameclock2secs(x):\n",
    "        clock = x.split(\":\")\n",
    "        return (60 * int(clock[0])) + int(clock[1])        \n",
    "        \n",
    "    def group_stadium_types(stadium):\n",
    "        outdoor = [\n",
    "            'Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', \n",
    "            'Outside', 'Outddors','Outdoor Retr Roof-Open', 'Oudoor', 'Bowl'\n",
    "            ]\n",
    "        indoor_closed = [\n",
    "            'Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed',\n",
    "            'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed',\n",
    "        ]\n",
    "        indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "        dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "        dome_open     = ['Domed, Open', 'Domed, open']\n",
    "        if stadium in outdoor:\n",
    "            return 0 #'outdoor'\n",
    "        elif stadium in indoor_closed:\n",
    "            return 3 # 'indoor closed'\n",
    "        elif stadium in indoor_open:\n",
    "            return 2 #'indoor open'\n",
    "        elif stadium in dome_closed:\n",
    "            return 4 #'dome closed'\n",
    "        elif stadium in dome_open:\n",
    "            return 1 #'dome open'\n",
    "        else:\n",
    "            return 5 #'unknown'\n",
    "        \n",
    "    def group_game_weather(weather):\n",
    "        rain = [\n",
    "            'Rainy', 'Rain Chance 40%', 'Showers',\n",
    "            'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "            'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain'\n",
    "        ]\n",
    "        overcast = [\n",
    "            'Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n",
    "            'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n",
    "            'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n",
    "            'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n",
    "            'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n",
    "            'Partly Cloudy', 'Cloudy'\n",
    "        ]\n",
    "        clear = [\n",
    "            'Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n",
    "            'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n",
    "            'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n",
    "            'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n",
    "            'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n",
    "            'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny'\n",
    "        ]\n",
    "        snow  = ['Heavy lake effect snow', 'Snow']\n",
    "        none  = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n",
    "        if weather in rain:\n",
    "            return -1 #'rain'\n",
    "        elif weather in overcast:\n",
    "            return 1 #'overcast'\n",
    "        elif weather in clear:\n",
    "            return 2 #'clear'\n",
    "        elif weather in snow:\n",
    "            return -2 #snow'\n",
    "        elif weather in none:\n",
    "            return 0 #'none'        \n",
    "        \n",
    "    def clean_wind_speed(windspeed):\n",
    "        \"\"\"\n",
    "        This is not a very robust function,\n",
    "        but it should do the job for this dataset.\n",
    "        \"\"\"\n",
    "        ws = str(windspeed)\n",
    "        # if it's already a number just return an int value\n",
    "        if ws.isdigit():\n",
    "            return int(ws)\n",
    "        # if it's a range, take their mean\n",
    "        if '-' in ws:\n",
    "            return (int(ws.split('-')[0]) + int(ws.split('-')[1]))/2\n",
    "        # if there's a space between the number and mph\n",
    "        if ws.split(' ')[0].isdigit():\n",
    "            return int(ws.split(' ')[0])\n",
    "        # if it looks like '10MPH' or '12mph' just take the first part\n",
    "        if 'mph' in ws.lower():\n",
    "            return int(ws.lower().split('mph')[0])\n",
    "        else:\n",
    "            return 0   \n",
    "            \n",
    "    def clean_wind_direction(wind_direction):\n",
    "        wd = str(wind_direction).upper()\n",
    "        if wd == 'N' or 'FROM S' in wd:\n",
    "            return 90 #'north'\n",
    "        if wd == 'S' or 'FROM N' in wd:\n",
    "            return 270 #'south'\n",
    "        if wd == 'W' or 'FROM E' in wd:\n",
    "            return 180 #'west'\n",
    "        if wd == 'E' or 'FROM W' in wd:\n",
    "            return 0 #'east'\n",
    "        if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n",
    "            return 45 #'north east'\n",
    "        if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n",
    "            return 135 #'north west'\n",
    "        if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n",
    "            return 315 #'south east'\n",
    "        if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n",
    "            return 225 #'south west'\n",
    "        if 'NW' in wd or 'NORTHWEST' in wd:\n",
    "            return 135 #'north west'\n",
    "        if 'NE' in wd or 'NORTH EAST' in wd:\n",
    "            return 45 #'north east'\n",
    "        if 'SW' in wd or 'SOUTHWEST' in wd:\n",
    "            return 225 #'south west'\n",
    "        if 'SE' in wd or 'SOUTHEAST' in wd:\n",
    "            return 315 #'south east'            \n",
    "            \n",
    "    def birthday2day(x):\n",
    "        days = x.split(\"/\")\n",
    "        return 30 * int(days[0]) + int(days[1]) + 365 * int(days[2])\n",
    "    \n",
    "    def height2inch(x):\n",
    "        height = x.split(\"-\")\n",
    "        return 12 * int(height[0]) + int(height[1])    \n",
    "    \n",
    "    def uid_aggregation(comb, main_columns, uids, aggregations):\n",
    "        X = pd.DataFrame()\n",
    "        for main_column in main_columns:  \n",
    "            for col in uids:\n",
    "                for agg_type in aggregations:\n",
    "                    new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                    temp_df = comb[[col, main_column]]\n",
    "                    temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                            columns={agg_type: new_col_name})\n",
    "    \n",
    "                    temp_df.index = list(temp_df[col])\n",
    "                    temp_df = temp_df[new_col_name].to_dict()   \n",
    "    \n",
    "                    X[new_col_name] = comb[col].map(temp_df)\n",
    "                    del temp_df\n",
    "                    gc.collect()\n",
    "        return X\n",
    "    \n",
    "    df['ToLeft'] = df.PlayDirection == \"left\"\n",
    "    # Match the NFLId to that play's rusher's ID\n",
    "    df['IsBallCarrier'] = df.NflId == df.NflIdRusher \n",
    "    \n",
    "    # Correct differences in Team Name abbreviations\n",
    "    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n",
    "    for abb in df['PossessionTeam'].unique():\n",
    "        map_abbr[abb] = abb\n",
    "    \n",
    "    # New feature to show Dir in radians\n",
    "    df['Dir_rad'] = np.mod(90 - df.Dir, 360) * math.pi/180.0\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    \n",
    "    # IsOnOffense\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense \n",
    "    \n",
    "    df['YardLine_std'] = 100 - df.YardLine\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "              'YardLine_std'\n",
    "             ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "              'YardLine']\n",
    "    df['X_std'] = df.X\n",
    "    df.loc[df.ToLeft, 'X_std'] = 120 - df.loc[df.ToLeft, 'X'] \n",
    "    df['Y_std'] = df.Y\n",
    "    df.loc[df.ToLeft, 'Y_std'] = 160/3 - df.loc[df.ToLeft, 'Y'] \n",
    "    df['Orientation_std'] = -90 + df.Orientation\n",
    "    df['Dir_std'] = df['Dir_rad']\n",
    "    df.loc[df.ToLeft, 'Dir_std'] = np.mod(np.pi + df.loc[df.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "    \n",
    "    # Clean Position feature\n",
    "    df['Position'] = df['Position'].apply(clean_position)\n",
    "    \n",
    "    # OffenseTeam & DefenseTeam\n",
    "    df = df.rename(columns = {'PossessionTeam':'OffenseTeam'}) \n",
    "    df['DefenseTeam'] = df['VisitorTeamAbbr']\n",
    "    df.loc[df.TeamOnOffense == 'away', 'DefenseTeam'] = df['HomeTeamAbbr']\n",
    "    \n",
    "    # IsOffenseAtHome\n",
    "    df['IsOffenseAtHome'] = True\n",
    "    df.loc[df.TeamOnOffense == 'away', 'IsOffenseAtHome'] = False\n",
    "    \n",
    "    # OffenseScore\n",
    "    df['OffenseScore'] = df['HomeScoreBeforePlay']\n",
    "    df.loc[df.TeamOnOffense == 'away', 'OffenseScore'] = df['VisitorScoreBeforePlay']\n",
    "    \n",
    "    # DefenseScore\n",
    "    df['DefenseScore'] = df['VisitorScoreBeforePlay']\n",
    "    df.loc[df.TeamOnOffense == 'away', 'DefenseScore'] = df['HomeScoreBeforePlay']\n",
    "    \n",
    "    # IsOffenseWinning\n",
    "    df['IsOffenseWinning'] = False\n",
    "    df.loc[df.OffenseScore > df.DefenseScore, 'IsOffenseWinning'] = True\n",
    "    \n",
    "    # OffenseInOwnTerritory\n",
    "    df['OffenseInOwnTerritory'] = False\n",
    "    df.loc[df.FieldPosition == df.OffenseTeam, 'OffenseInOwnTerritory'] = True\n",
    "    \n",
    "    # OffenseRushingPosition\n",
    "    play_rushers = df.loc[df.NflIdRusher == df.NflId, ['PlayId', 'Position']]\n",
    "    play_rushers = play_rushers.rename(columns={'Position': 'OffenseRushingPosition'})\n",
    "    df = df.merge(play_rushers, how='left', left_on='PlayId', right_on='PlayId')\n",
    "    \n",
    "    # OffenceFormation\n",
    "    df['OffenseFormation'] = df['OffenseFormation'].apply(clean_offenceformation)\n",
    "    df['OffenseFormation'] = df['OffenseFormation'].fillna(7)\n",
    "    \n",
    "    # NumberOfTEsOnPlay, NumberOfWRsOnPlay, NumberOfBacksOnPlay, ....\n",
    "    df['GeneralPosition'] = df['Position'].apply(create_generalposition)\n",
    "    # Pivot to find counts of each general position\n",
    "    gen_pos_counts = df[['PlayId','GeneralPosition']].pivot_table(index='PlayId', columns='GeneralPosition', \n",
    "                                                                  aggfunc=len, fill_value=0)\n",
    "    gen_pos_counts = gen_pos_counts.rename(columns = \n",
    "                          {'DB':'NumberOfDBsOnPlay', 'DL':'NumberOfDLinemenOnPlay', \n",
    "                           'LB':'NumberOfLBsOnPlay', 'OB':'NumberOfBacksOnPlay',\n",
    "                           'OL':'NumberOfOLinemenOnPlay', 'TE':'NumberOfTEsOnPlay',\n",
    "                           'WR':'NumberOfWRsOnPlay'})\n",
    "    df = df.merge(gen_pos_counts, how='left', left_on='PlayId', right_on='PlayId')\n",
    "    \n",
    "    # DefendersInTheBox\n",
    "    df['DefendersInTheBox'] = df['DefendersInTheBox'].fillna(df['DefendersInTheBox'].median())\n",
    "    \n",
    "    # TimeBetweenSnapHandoff, Month, ...\n",
    "    df['TimeBetweenSnapHandoff'] = df['TimeHandoff'].apply(utc2sec) - df['TimeSnap'].apply(utc2sec)\n",
    "    df['MatchDay'] = df['TimeSnap'].apply(timesnap2day)\n",
    "    df['DayOfYear'] = pd.to_datetime(df['TimeSnap'].apply(timesnap2date)).dt.dayofyear\n",
    "    df['DayOfWeek'] = pd.to_datetime(df['TimeSnap'].apply(timesnap2date)).dt.dayofweek\n",
    "    df['MonthOfYear'] = df['TimeSnap'].apply(lambda x : int(x[5:7]))\n",
    "    df['Morning'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) >=0 and int(x[11:13]) <12) else 0)\n",
    "    df['Afternoon'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) <18 and int(x[11:13]) >=12) else 0)\n",
    "    df['Evening'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) >= 18 and int(x[11:13]) < 24) else 0)\n",
    "\n",
    "    # QuarterGameSecs, TotalGameSecsPlayed, HalfGameSecs\n",
    "    df['QuarterGameSecs'] = df['GameClock'].apply(gameclock2secs)\n",
    "    df['TotalGameSecsPlayed'] = (900 - df['QuarterGameSecs']) + ((df['Quarter'] - 1) * 900)\n",
    "    df['HalfGameSecsLeft'] = df['QuarterGameSecs']\n",
    "    df.loc[(df['Quarter'].isin([1,3])), 'HalfGameSecsLeft'] = (900 + df['QuarterGameSecs'])\n",
    "    \n",
    "    # IsInEngland\n",
    "    df['IsInEngland'] = df[\"Location\"].str.lower().map(lambda x: True if \"london\" in x else False)\n",
    "    \n",
    "    # StadiumType\n",
    "    # from https://www.kaggle.com/code1110/optimizing-lightgbm-hyperparameters\n",
    "    df['StadiumType'] = df['StadiumType'].apply(group_stadium_types)\n",
    "    \n",
    "    # Turf\n",
    "    # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\n",
    "    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n",
    "            'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n",
    "            'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n",
    "            'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n",
    "            'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "    df['Turf'] = df['Turf'].map(Turf)\n",
    "    df['Turf'] = df['Turf'].map({\"Natural\": 0,\"Artificial\": 1})\n",
    "    \n",
    "    # GameWeather\n",
    "    # https://www.kaggle.com/code1110/optimizing-lightgbm-hyperparameters\n",
    "    df['GameWeather'] = df['GameWeather'].apply(group_game_weather)\n",
    "        \n",
    "    # Temperature \n",
    "    df['Temperature'] = df['Temperature'].fillna(df['Temperature'].median())\n",
    "    \n",
    "    # Humidity\n",
    "    df['Humidity'] = df['Humidity'].fillna(df['Humidity'].median())\n",
    "    \n",
    "    # WindSpeed\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(clean_wind_speed)\n",
    "    \n",
    "    # WindDirection\n",
    "    # from https://www.kaggle.com/code1110/optimizing-lightgbm-hyperparameters\n",
    "    df['WindDirection'] = df['WindDirection'].apply(clean_wind_direction)\n",
    "    df['WindDirection'] = 2 * np.pi * (90 - df['WindDirection']) / 360\n",
    "    \n",
    "    # Team\n",
    "    df['Team'] = df['Team'].map({\"home\": 0, \"away\": 1})\n",
    "    \n",
    "    # Dir\n",
    "    df[\"Dir\"] = np.mod(90 - df[\"Dir\"].values, 360)\n",
    "    \n",
    "    # PlayerBirthDate\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(birthday2day)\n",
    "    \n",
    "    # PlayerAge\n",
    "    df['PlayerAge'] = df['MatchDay'] - df['PlayerBirthDate']\n",
    "    \n",
    "    # PlayDirection\n",
    "    df['PlayDirection'] = df['PlayDirection'].map({'right': 1, 'left': -1})\n",
    "    \n",
    "    # PlayerWeight\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(height2inch)\n",
    "    \n",
    "    # PlayerBMI\n",
    "    df['PlayerBMI'] = df['PlayerWeight'] / df['PlayerHeight']\n",
    "    \n",
    "    # SecondsNeedToFirstDown\n",
    "    # from https://www.kaggle.com/ryches/model-free-benchmark\n",
    "    df['SecondsNeedToFirstDown'] = (df['Distance']*0.9144) / (df['Dis'].values + 0.01)\n",
    "    \n",
    "    # SecondsNeedToYardLine\n",
    "    # from https://www.kaggle.com/ryches/model-free-benchmark\n",
    "    df['SecondsNeedToYardLine'] = (df['YardLine']*0.9144) / (df['Dis'].values + 0.01)\n",
    "    \n",
    "    # DefendersInTheBox_vs_Distance\n",
    "    # from https://www.kaggle.com/ryches/model-free-benchmark\n",
    "    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n",
    "    \n",
    "    # Start\n",
    "    # from https://www.kaggle.com/sryo188558/cox-proportional-hazard-model\n",
    "    df[\"Start\"] = df[\"YardLine\"]\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == 1), \"Start\"] = df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == 1), \n",
    "                                                                                       \"YardLine\"] + 10\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == -1), \"Start\"] = 120 - df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == -1), \n",
    "                                                                                       \"YardLine\"] - 10\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == 1), \"Start\"] = 120 - df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == 1), \n",
    "                                                                                       \"YardLine\"] - 10\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == -1), \"Start\"] = df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == -1), \n",
    "                                                                                       \"YardLine\"] + 10\n",
    "    # Orientation \n",
    "    df['Orientation'] = 2 * np.pi * (90 - df['Orientation']) / 360\n",
    "    \n",
    "    # locX\n",
    "    df['locX'] = (df['X'].values - df['Start'].values) * df['PlayDirection'].values\n",
    "    \n",
    "    # locY\n",
    "    df['locY'] = df['Y'].values - 53.3 / 2\n",
    "    \n",
    "    # velX\n",
    "    df['velX'] = df['S'].values * np.cos(df['Orientation'].values) * df['PlayDirection'].values\n",
    "    \n",
    "    # velY\n",
    "    df['velY'] = df['S'].values * np.sin(df['Orientation'].values)\n",
    "    \n",
    "    # accX\n",
    "    df['accX'] = df['A'].values * np.cos(df['Orientation'].values) * df['PlayDirection'].values\n",
    "    \n",
    "    # accY\n",
    "    df['accY'] = df['A'].values * np.sin(df['Orientation'].values)\n",
    "    \n",
    "    # Aggregations by NflId (each player)\n",
    "    i_cols = ['HomeScoreBeforePlay','VisitorScoreBeforePlay','YardLine']\n",
    "    uids = ['NflId']\n",
    "    aggregations = ['mean','std','median', 'max', 'min']\n",
    "    df_agg = uid_aggregation(df, i_cols, uids, aggregations)\n",
    "    df = pd.concat([df, df_agg], axis=1)\n",
    "    \n",
    "    # OffenseTeam & DefenseTeam dummies\n",
    "    df_train = pd.get_dummies(df, prefix=['OffenseTeam', 'DefenseTeam'], \n",
    "                              columns=['OffenseTeam', 'DefenseTeam'])\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols = ['index','GameId','PlayId','NflId','PlayDirection'\n",
    "           'Team','TeamOnOffense','HomeTeamAbbr','VisitorTeamAbbr',\n",
    "           'HomeScoreBeforePlay','VisitorScoreBeforePlay', \n",
    "           'FieldPosition','DisplayName','TimeHandoff','TimeSnap',\n",
    "           'DefensePersonnel', 'OffensePersonnel','GameClock',\n",
    "           'Location','NflIdRusher','PlayerCollegeName','Stadium',\n",
    "           'OffenseRushingPosition','Position','GeneralPosition',\n",
    "           'OffenseTeam','DefenseTeam']\n",
    "cat = []\n",
    "for f in df_train.columns :\n",
    "    if  (str(df_train[f].dtype)==\"object\" or str(df_train[f].dtype)==\"category\") :\n",
    "        cat.append(f)\n",
    "        \n",
    "features = list(df_train.columns)\n",
    "features =  [col for col in features if col not in  rm_cols + cat]\n",
    "#features = [c for c in df.columns.values if c not in rm_cols]\n",
    "#df_train = df[features]\n",
    "#print(df_train.shape)\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(features),'FEATURES.')\n",
    "np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/hukuda222/nfl-simple-model-using-lightgbm\n",
    "train_data = np.zeros((509762//22,len(features)))\n",
    "for i in tqdm.tqdm(range(21,509762,22)):\n",
    "    count=0\n",
    "    for c in features:\n",
    "        train_data[i//22][count] = df_train[c][i]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=train_data,columns=features)\n",
    "y_tr_ = np.array([df_train[\"Yards\"][i] for i in range(21,509762,22)])\n",
    "y_tr = np.zeros(len(y_tr_),dtype=np.float)\n",
    "for i in range(len(y_tr)):\n",
    "    y_tr[i]=(y_tr_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _EvalFunction(labels,predictions) :\n",
    "    \n",
    "    #predictions,labels = np.round(scaler.inverse_transform(predictions)),np.round(scaler.inverse_transform(labels))\n",
    "    n = np.arange(-99, 100)\n",
    "    n = np.row_stack([n] * predictions.shape[0])\n",
    "    ym = labels.reshape(predictions.shape[0], 1)\n",
    "    step_ym = np.heaviside(n - ym, 1)\n",
    "    yn = predictions.reshape(labels.shape[0], 1)\n",
    "    step_yn = np.heaviside(n - yn, 1)\n",
    "    inner_sum = np.power(step_yn - step_ym, 2)\n",
    "    inner_sum = inner_sum.sum(axis=1)\n",
    "    total = inner_sum.sum() / (199 * predictions.shape[0])\n",
    "                           \n",
    "    return 'CRPS', total, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lgb = {'lambda_l1': 0.13413394854686794, \n",
    "                   'lambda_l2': 0.0009122197743451751, \n",
    "                   'num_leaves': 44, \n",
    "                   'feature_fraction': 0.4271070738920401, \n",
    "                   'bagging_fraction': 0.9999128827046064, \n",
    "                   'bagging_freq': 3, \n",
    "                   \"learning_rate\": 0.005,\n",
    "                   'min_child_samples': 43, \n",
    "                   'objective': 'regression', \n",
    "                   'metric': 'mae', \n",
    "                   'verbosity': -1, \n",
    "                   'boosting_type': 'gbdt', \n",
    "                   \"boost_from_average\" : False,\n",
    "                   'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "nfold = 5\n",
    "folds = KFold(n_splits=nfold, shuffle=False, random_state=42)\n",
    "\n",
    "print('-'*20)\n",
    "print(str(nfold) + ' Folds training...')\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.zeros(len(X_train))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "tr_mae = []\n",
    "val_mae = []\n",
    "models = []\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train,y_tr)):\n",
    "    strLog = \"fold {}\".format(fold_)\n",
    "    print(strLog)\n",
    "\n",
    "    X_tr, X_val = df_train.iloc[trn_idx][features], df_train.iloc[val_idx][features]\n",
    "    train_y, y_val = y_tr[trn_idx], y_tr[val_idx]\n",
    "\n",
    "    model = lgb.LGBMRegressor(**best_params_lgb, n_estimators = 180, n_jobs = -1)\n",
    "    model.fit(X_tr, \n",
    "              train_y, \n",
    "              eval_set=[(X_tr, train_y), (X_val, y_val)], \n",
    "              eval_metric=_EvalFunction,\n",
    "              verbose=10, \n",
    "              early_stopping_rounds=500,\n",
    "              \n",
    "             )\n",
    "    oof[val_idx] = model.predict(X_val)\n",
    "    val_score = mean_absolute_error(y_val, oof[val_idx])\n",
    "    val_mae.append(val_score)\n",
    "    tr_score = mean_absolute_error(train_y, model.predict(X_tr))\n",
    "    tr_mae.append(tr_score)\n",
    "    models.append(model)\n",
    "    \n",
    "    # Feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = X_tr.columns\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_[:len(X_tr.columns)]\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mae_tr = np.mean(tr_mae)\n",
    "std_mae_tr =  np.std(tr_mae)\n",
    "\n",
    "mean_mae_val =  np.mean(val_mae)\n",
    "std_mae_val =  np.std(val_mae)\n",
    "\n",
    "all_mae = mean_absolute_error(oof,y_tr)\n",
    "\n",
    "print('-'*20)\n",
    "print(\"Train's Score\")\n",
    "print('-'*20,'\\n')\n",
    "print(\"Mean mae: %.5f, std: %.5f.\" % (mean_mae_tr, std_mae_tr),'\\n')\n",
    "\n",
    "print('-'*20)\n",
    "print(\"Validation's Score\")\n",
    "print('-'*20,'\\n')\n",
    "print(\"Mean mae: %.5f, std: %.5f.\" % (mean_mae_val, std_mae_val),'\\n')\n",
    "\n",
    "print(\"All mae: %.5f.\" % (all_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_imp = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:50].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols_imp)]\n",
    "\n",
    "plt.figure(figsize=(14,26))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('LightGBM Features (averaged over folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EvalFunction(y_tr,oof)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "for (test_df, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n",
    "    test = preprocess(test_df)\n",
    "    count=0\n",
    "    test_data = np.zeros((1,len(features)))\n",
    "    for c in features:\n",
    "        try:\n",
    "            test_data[0][count] = test[c][index]\n",
    "        except:\n",
    "            test_data[0][count] = np.nan\n",
    "        count+=1\n",
    "        \n",
    "    y_pred = np.zeros(199)        \n",
    "    y_pred_p = np.mean([model.predict(test_data)[0] for model in models])\n",
    "\n",
    "    y_pred_p += 99\n",
    "    for j in range(199):\n",
    "        if j>=y_pred_p+10:\n",
    "            y_pred[j]=1.0\n",
    "        elif j>=y_pred_p-10:\n",
    "            y_pred[j]=(j+10-y_pred_p)*0.05\n",
    "\n",
    "    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n",
    "    index += 22\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unused functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_football_field(linenumbers=True,\n",
    "                          endzones=True,\n",
    "                          highlight_line=False,\n",
    "                          highlight_line_number=50,\n",
    "                          highlighted_name='Line of Scrimmage',\n",
    "                          fifty_is_los=False,\n",
    "                          figsize=(12*2, 6.33*2)):\n",
    "    \"\"\"\n",
    "    Function that plots the football field for viewing plays.\n",
    "    Allows for showing or hiding endzones.\n",
    "    \"\"\"\n",
    "    rect = patches.Rectangle((0, 0), 120, 53.3, linewidth=0.1,\n",
    "                             edgecolor='r', facecolor='darkgreen', zorder=0,  alpha=0.5)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    ax.add_patch(rect)\n",
    "    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n",
    "              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n",
    "             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n",
    "              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n",
    "             color='white')\n",
    "    if fifty_is_los:\n",
    "        plt.plot([60, 60], [0, 53.3], color='gold')\n",
    "        plt.text(62, 50, '<- Player Yardline at Snap', color='gold')\n",
    "    # Endzones\n",
    "    if endzones:\n",
    "        ez1 = patches.Rectangle((0, 0), 10, 53.3,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        ez2 = patches.Rectangle((110, 0), 120, 53.3,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        ax.add_patch(ez1)\n",
    "        ax.add_patch(ez2)\n",
    "    plt.xlim(0, 120)\n",
    "    plt.ylim(-5, 58.3)\n",
    "    plt.axis('off')\n",
    "    if linenumbers:\n",
    "        for x in range(20, 110, 10):\n",
    "            numb = x\n",
    "            if x > 50:\n",
    "                numb = 120 - x\n",
    "            plt.text(x, 5, str(numb - 10),\n",
    "                     horizontalalignment='center',\n",
    "                     fontsize=20,  # fontname='Arial',\n",
    "                     color='white')\n",
    "            plt.text(x - 0.95, 53.3 - 5, str(numb - 10),\n",
    "                     horizontalalignment='center',\n",
    "                     fontsize=20,  # fontname='Arial',\n",
    "                     color='white', rotation=180)\n",
    "    if endzones:\n",
    "        hash_range = range(11, 110)\n",
    "    else:\n",
    "        hash_range = range(1, 120)\n",
    "    for x in hash_range:\n",
    "        ax.plot([x, x], [0.4, 0.7], color='white')\n",
    "        ax.plot([x, x], [53.0, 52.5], color='white')\n",
    "        ax.plot([x, x], [22.91, 23.57], color='white')\n",
    "        ax.plot([x, x], [29.73, 30.39], color='white')\n",
    "    if highlight_line:\n",
    "        hl = highlight_line_number + 10\n",
    "        plt.plot([hl, hl], [0, 53.3], color='yellow')\n",
    "        plt.text(hl + 2, 50, '<- {}'.format(highlighted_name),\n",
    "                 color='yellow')\n",
    "    return fig, ax\n",
    "#create_football_field()\n",
    "\n",
    "def get_dx_dy(radian_angle, dist):\n",
    "    dx = dist * math.cos(radian_angle)\n",
    "    dy = dist * math.sin(radian_angle)\n",
    "    return dx, dy\n",
    "def show_play(play_id, df=df):\n",
    "    df = df[df.PlayId == play_id]\n",
    "    fig, ax = create_football_field()\n",
    "    ax.scatter(df.X, df.Y, cmap='rainbow', c=~(df.Team == 'home'), s=100)\n",
    "    rusher_row = df[df.NflIdRusher == df.NflId]\n",
    "    ax.scatter(rusher_row.X, rusher_row.Y, color='black')\n",
    "    yards_covered = rusher_row[\"Yards\"].values[0]\n",
    "    x = rusher_row[\"X\"].values[0]\n",
    "    y = rusher_row[\"Y\"].values[0]\n",
    "    rusher_dir = rusher_row[\"Dir_rad\"].values[0]\n",
    "    rusher_speed = rusher_row[\"S\"].values[0]\n",
    "    dx, dy = get_dx_dy(rusher_dir, rusher_speed)\n",
    "    ax.arrow(x, y, dx, dy, length_includes_head=True, width=0.3, color='black')\n",
    "    left = 'left' if df.ToLeft.sum() > 0 else 'right'\n",
    "    plt.title(f'Play # {play_id} moving to {left}, yard distance is {yards_covered}', fontsize=20)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wrote the helper function below to combine all files within a \n",
    "# folder into a single file to submit in Kaggle.\n",
    "\n",
    "def generate_submission(path=None, closing_file='_closing_submission.py',\n",
    "                        submission_file='submissions/submission.py'):\n",
    "    \"\"\"This function combines all PY files into a single submission file, to\n",
    "    be uploaded as a single script in Kaggle.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path from within combine PY files. If None, will use\n",
    "            current\n",
    "        closing_file (str): The last file to be added to the submission file.\n",
    "            It contains the final function to be executed in the script.\n",
    "        submission_file (str): The final submission file\n",
    "\n",
    "    \"\"\"\n",
    "    if path is None or not os.path.exists(path):\n",
    "        path = os.getcwd()\n",
    "\n",
    "    dest = open(os.path.join(path, submission_file), \"w\")\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".py\") and not filename.startswith('_'):\n",
    "            f = open(os.path.join(path, filename), \"r\")\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('from nfl.'):\n",
    "                    continue\n",
    "                if line.startswith(\"if __name__ == \"):\n",
    "                    break\n",
    "\n",
    "                dest.write(line)\n",
    "\n",
    "            dest.write('\\n\\n')\n",
    "            dest.write('#' + '*' * 79)\n",
    "            dest.write('\\n\\n')\n",
    "            f.close()\n",
    "\n",
    "    if not os.path.exists(closing_file):\n",
    "        raise ValueError('Closing file does not exist!')\n",
    "\n",
    "    f = open(os.path.join(path, closing_file), \"r\")\n",
    "    dest.write(f.read())\n",
    "    dest.close()\n",
    "    \n",
    "    \n",
    "    # Better organizing the code in a proper file structure helped \n",
    "    # me figure out faster & better ways to develop & improve my algorithms. It enabled my very final code becoming something very neat:\n",
    "#n_splits = 5\n",
    "#dataset = Dataset('/kaggle/input/nfl-big-data-bowl-2020/train.csv')\n",
    "#model1 = KerasModel(n_splits=n_splits, input_dim=103)\n",
    "#model2 = XGBModel(n_splits=n_splits)\n",
    "#model3 = LGBModel(n_splits=n_splits)\n",
    "#model4 = CatBoostModel(n_splits=n_splits)\n",
    "#ensemble = Ensemble(models=[model1, model2, model3, model4], dataset=dataset)\n",
    "#ensemble.train()\n",
    "#env = nflrush.make_env()\n",
    "#ensemble.make_submission(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "a8dae707-2c7a-4728-90dd-23e595076851"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
