{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# NFL Big Data Bowl - Feature Engineering v1\n",
    "-------------------\n",
    "TheNerdyCat <br>\n",
    "Created: 2019/10/27 <br>\n",
    "Deadline: 2019/11/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "import kaggle\n",
    "import math\n",
    "import datetime\n",
    "import random\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#import lightgbm as lgb\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "#import optuna\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [15,10]\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509762, 49)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/nfl-big-data-bowl-2020/train.csv\", low_memory=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "\n",
    "    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n",
    "            'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n",
    "            'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n",
    "            'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n",
    "            'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "    \n",
    "    # from https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win\n",
    "    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n",
    "    for abb in df['PossessionTeam'].unique():\n",
    "        map_abbr[abb] = abb\n",
    "    \n",
    "    def clean_position(pos):\n",
    "        if pos == 'SAF':\n",
    "            return 'DB'\n",
    "        if pos == 'S':\n",
    "            return 'DB'\n",
    "        elif pos == 'OG':\n",
    "            return 'G'\n",
    "        elif pos == \"OT\":\n",
    "            return 'T'\n",
    "        else:\n",
    "            return pos\n",
    "    \n",
    "    def clean_offenceformation(of):\n",
    "        if of == \"SHOTGUN\":\n",
    "            return 9\n",
    "        elif of == \"SINGLEBACK\":\n",
    "            return 8\n",
    "        elif of == \"JUMBO\":\n",
    "            return 6\n",
    "        elif of == \"PISTOL\":\n",
    "            return 5\n",
    "        elif of == \"I_FORM\":\n",
    "            return 4\n",
    "        elif of == \"ACE\":\n",
    "            return 3\n",
    "        elif of ==  \"WILDCAT\":\n",
    "            return 2\n",
    "        elif of == \"EMPTY\":\n",
    "            return 1\n",
    "        else: \n",
    "            return 7\n",
    "    \n",
    "    def create_generalposition(pos):\n",
    "        if pos == 'SS' or pos == 'FS' or pos == 'CB' or pos == 'DB':\n",
    "            return 'DB'\n",
    "        elif pos == 'DE' or pos == 'DT' or pos == 'DL':\n",
    "            return 'DL'\n",
    "        elif pos == 'ILB' or pos == 'OLB' or pos == 'MLB' or pos == 'LB':\n",
    "            return 'LB'\n",
    "        elif pos == 'WR':\n",
    "            return 'WR'\n",
    "        elif pos == 'TE':\n",
    "            return 'TE'\n",
    "        elif pos == 'T' or pos == 'G' or pos == 'C' or pos == 'NT' or pos == 'OL':\n",
    "            return 'OL'\n",
    "        elif pos == 'QB' or pos == 'RB' or pos == 'FB' or pos == 'HB' or pos == 'TB' or pos == 'WB':\n",
    "            return 'OB'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    def utc2sec(x):\n",
    "        return int(x.split(\"-\")[2].split(\":\")[2].split(\".\")[0])\n",
    "    def timesnap2date(x):\n",
    "        day = x.split(\"T\")[0]\n",
    "        return day\n",
    "    def timesnap2day(x):\n",
    "        days = x.split(\"-\")\n",
    "        return 365 * int(days[0]) + 30 * int(days[1]) + int(days[2][:2])\n",
    "    def gameclock2secs(x):\n",
    "        clock = x.split(\":\")\n",
    "        return (60 * int(clock[0])) + int(clock[1])        \n",
    "        \n",
    "    def group_stadium_types(stadium):\n",
    "        outdoor = [\n",
    "            'Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', \n",
    "            'Outside', 'Outddors','Outdoor Retr Roof-Open', 'Oudoor', 'Bowl'\n",
    "            ]\n",
    "        indoor_closed = [\n",
    "            'Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed',\n",
    "            'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed',\n",
    "        ]\n",
    "        indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "        dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "        dome_open     = ['Domed, Open', 'Domed, open']\n",
    "        if stadium in outdoor:\n",
    "            return 0 #'outdoor'\n",
    "        elif stadium in indoor_closed:\n",
    "            return 3 # 'indoor closed'\n",
    "        elif stadium in indoor_open:\n",
    "            return 2 #'indoor open'\n",
    "        elif stadium in dome_closed:\n",
    "            return 4 #'dome closed'\n",
    "        elif stadium in dome_open:\n",
    "            return 1 #'dome open'\n",
    "        else:\n",
    "            return 5 #'unknown'\n",
    "        \n",
    "    def map_weather(txt):\n",
    "        ans = 1\n",
    "        if pd.isna(txt):\n",
    "            return 0\n",
    "        if 'partly' in txt:\n",
    "            ans*=0.5\n",
    "        if 'climate controlled' in txt or 'indoor' in txt:\n",
    "            return ans*3\n",
    "        if 'sunny' in txt or 'sun' in txt:\n",
    "            return ans*2\n",
    "        if 'clear' in txt:\n",
    "            return ans\n",
    "        if 'cloudy' in txt:\n",
    "            return -ans\n",
    "        if 'rain' in txt or 'rainy' in txt:\n",
    "            return -2*ans\n",
    "        if 'snow' in txt:\n",
    "            return -3*ans\n",
    "        return 0       \n",
    "        \n",
    "    def clean_wind_speed(windspeed):\n",
    "        \"\"\"\n",
    "        This is not a very robust function,\n",
    "        but it should do the job for this dataset.\n",
    "        \"\"\"\n",
    "        ws = str(windspeed)\n",
    "        # if it's already a number just return an int value\n",
    "        if ws.isdigit():\n",
    "            return int(ws)\n",
    "        # if it's a range, take their mean\n",
    "        if '-' in ws:\n",
    "            return (int(ws.split('-')[0]) + int(ws.split('-')[1]))/2\n",
    "        # if there's a space between the number and mph\n",
    "        if ws.split(' ')[0].isdigit():\n",
    "            return int(ws.split(' ')[0])\n",
    "        # if it looks like '10MPH' or '12mph' just take the first part\n",
    "        if 'mph' in ws.lower():\n",
    "            return int(ws.lower().split('mph')[0])\n",
    "        else:\n",
    "            return 0   \n",
    "            \n",
    "    def clean_WindDirection(txt):\n",
    "        if pd.isna(txt):\n",
    "            return np.nan\n",
    "        txt = txt.lower()\n",
    "        txt = ''.join([c for c in txt if c not in punctuation])\n",
    "        txt = txt.replace('from', '')\n",
    "        txt = txt.replace(' ', '')\n",
    "        txt = txt.replace('north', 'n')\n",
    "        txt = txt.replace('south', 's')\n",
    "        txt = txt.replace('west', 'w')\n",
    "        txt = txt.replace('east', 'e')\n",
    "        return txt         \n",
    "        \n",
    "    def transform_WindDirection(txt):\n",
    "        if pd.isna(txt):\n",
    "            return np.nan\n",
    "        \n",
    "        if txt=='n':\n",
    "            return 0\n",
    "        if txt=='nne' or txt=='nen':\n",
    "            return 1/8\n",
    "        if txt=='ne':\n",
    "            return 2/8\n",
    "        if txt=='ene' or txt=='nee':\n",
    "            return 3/8\n",
    "        if txt=='e':\n",
    "            return 4/8\n",
    "        if txt=='ese' or txt=='see':\n",
    "            return 5/8\n",
    "        if txt=='se':\n",
    "            return 6/8\n",
    "        if txt=='ses' or txt=='sse':\n",
    "            return 7/8\n",
    "        if txt=='s':\n",
    "            return 8/8\n",
    "        if txt=='ssw' or txt=='sws':\n",
    "            return 9/8\n",
    "        if txt=='sw':\n",
    "            return 10/8\n",
    "        if txt=='sww' or txt=='wsw':\n",
    "            return 11/8\n",
    "        if txt=='w':\n",
    "            return 12/8\n",
    "        if txt=='wnw' or txt=='nww':\n",
    "            return 13/8\n",
    "        if txt=='nw':\n",
    "            return 14/8\n",
    "        if txt=='nwn' or txt=='nnw':\n",
    "            return 15/8\n",
    "        return np.nan\n",
    "        \n",
    "    def birthday2day(x):\n",
    "        days = x.split(\"/\")\n",
    "        return 30 * int(days[0]) + int(days[1]) + 365 * int(days[2])\n",
    "    \n",
    "    def height2inch(x):\n",
    "        height = x.split(\"-\")\n",
    "        return 12 * int(height[0]) + int(height[1])    \n",
    "    \n",
    "    def str_to_float(txt):\n",
    "        try:\n",
    "            return float(txt)\n",
    "        except:\n",
    "            return -1\n",
    "    df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n",
    "    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n",
    "    df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\n",
    "    \n",
    "    df['ToLeft'] = df.PlayDirection == \"left\"\n",
    "    # Match the NFLId to that play's rusher's ID\n",
    "    df['IsRusher'] = df.NflId == df.NflIdRusher \n",
    "    \n",
    "    # New feature to show Dir in radians\n",
    "    df['Dir_rad'] = np.mod(90 - df.Dir, 360) * math.pi/180.0\n",
    "    df['TeamOnOffense'] = \"home\"\n",
    "    df.loc[df.PossessionTeam != df.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    \n",
    "    # IsOnOffense\n",
    "    df['IsOnOffense'] = df.Team == df.TeamOnOffense \n",
    "    \n",
    "    df['YardLine_std'] = 100 - df.YardLine\n",
    "    df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "              'YardLine_std'\n",
    "             ] = df.loc[df.FieldPosition.fillna('') == df.PossessionTeam,  \n",
    "              'YardLine']\n",
    "    df['X_std'] = df.X\n",
    "    df.loc[df.ToLeft, 'X_std'] = 120 - df.loc[df.ToLeft, 'X'] \n",
    "    df['Y_std'] = df.Y\n",
    "    df.loc[df.ToLeft, 'Y_std'] = 160/3 - df.loc[df.ToLeft, 'Y'] \n",
    "    df['Orientation_std'] = -90 + df.Orientation\n",
    "    df['Dir_std'] = df['Dir_rad']\n",
    "    df.loc[df.ToLeft, 'Dir_std'] = np.mod(np.pi + df.loc[df.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "    \n",
    "    # Clean Position feature\n",
    "    df['Position'] = df['Position'].apply(clean_position)\n",
    "    \n",
    "    # IsOffenseAtHome\n",
    "    df['IsOffenseAtHome'] = True\n",
    "    df.loc[df.TeamOnOffense == 'away', 'IsOffenseAtHome'] = False\n",
    "    \n",
    "    # OffenseTeam & DefenseTeam\n",
    "    df['OffenseTeam'] = df['VisitorTeamAbbr']\n",
    "    df.loc[df.TeamOnOffense == 'home', 'OffenseTeam'] = df['HomeTeamAbbr']    \n",
    "    df['DefenseTeam'] = df['VisitorTeamAbbr']\n",
    "    df.loc[df.TeamOnOffense == 'away', 'DefenseTeam'] = df['HomeTeamAbbr']\n",
    "    \n",
    "    # OffenseScore\n",
    "    df['OffenseScore'] = df['HomeScoreBeforePlay']\n",
    "    df.loc[df.TeamOnOffense == 'away', 'OffenseScore'] = df['VisitorScoreBeforePlay']\n",
    "    \n",
    "    # DefenseScore\n",
    "    df['DefenseScore'] = df['VisitorScoreBeforePlay']\n",
    "    df.loc[df.TeamOnOffense == 'away', 'DefenseScore'] = df['HomeScoreBeforePlay']\n",
    "    \n",
    "    # IsOffenseWinning\n",
    "    df['IsOffenseWinning'] = False\n",
    "    df.loc[df.OffenseScore > df.DefenseScore, 'IsOffenseWinning'] = True\n",
    "    \n",
    "    # OffenseInOwnTerritory\n",
    "    df['OffenseInOwnTerritory'] = False\n",
    "    df.loc[df.FieldPosition == df.OffenseTeam, 'OffenseInOwnTerritory'] = True\n",
    "    \n",
    "    # OffenseRushingPosition\n",
    "    play_rushers = df.loc[df.NflIdRusher == df.NflId, ['PlayId', 'Position']]\n",
    "    play_rushers = play_rushers.rename(columns={'Position': 'OffenseRushingPosition'})\n",
    "    df = df.merge(play_rushers, how='outer', left_on='PlayId', right_on='PlayId')\n",
    "    \n",
    "    # OffenceFormation\n",
    "    df['OffenseFormation'] = df['OffenseFormation'].apply(clean_offenceformation)\n",
    "    df['OffenseFormation'] = df['OffenseFormation'].fillna(7)  \n",
    "    \n",
    "    \n",
    "    # NumberOfTEsOnPlay, NumberOfWRsOnPlay, NumberOfBacksOnPlay, ....\n",
    "    df['GeneralPosition'] = df['Position'].apply(create_generalposition)\n",
    "    df['NumberOfBacksOnPlay'] = 0\n",
    "    df['NumberOfOLinemenOnPlay'] = 0\n",
    "    df['NumberOfWRsOnPlay'] = 0\n",
    "    df['NumberOfTEsOnPlay'] = 0\n",
    "    df['NumberOfDBsOnPlay'] = 0\n",
    "    df['NumberOfDLinemenOnPlay'] = 0 \n",
    "    df['NumberOfLBsOnPlay'] = 0\n",
    "    # Pivot to find counts of each general position\n",
    "    gen_pos_counts = df[['PlayId','GeneralPosition']].pivot_table(index='PlayId', columns='GeneralPosition', \n",
    "                                                                  aggfunc=len, fill_value=0)\n",
    "    \n",
    "    gen_pos_counts = gen_pos_counts.rename(columns = \n",
    "                          {'DB':'NumberOfDBsOnPlay', 'DL':'NumberOfDLinemenOnPlay', \n",
    "                           'LB':'NumberOfLBsOnPlay', 'OB':'NumberOfBacksOnPlay',\n",
    "                           'OL':'NumberOfOLinemenOnPlay', 'TE':'NumberOfTEsOnPlay',\n",
    "                           'WR':'NumberOfWRsOnPlay'})\n",
    "    gen_pos_counts = gen_pos_counts.reset_index(drop=False)\n",
    "    del gen_pos_counts.columns.name\n",
    "    gen_pos_counts_cols = gen_pos_counts.columns.values.tolist()\n",
    "    gen_pos_counts = gen_pos_counts.loc[gen_pos_counts.index.repeat(22)].reset_index(drop=True)\n",
    "    df.update(gen_pos_counts)\n",
    "    \n",
    "    \n",
    "    # DefendersInTheBox\n",
    "    df['DefendersInTheBox'] = df['DefendersInTheBox'].fillna(df['DefendersInTheBox'].median())\n",
    "    \n",
    "    # TimeBetweenSnapHandoff, Month, ...\n",
    "    df['TimeBetweenSnapHandoff'] = df['TimeHandoff'].apply(utc2sec) - df['TimeSnap'].apply(utc2sec)\n",
    "    df['MatchDay'] = df['TimeSnap'].apply(timesnap2day)\n",
    "    df['DayOfYear'] = pd.to_datetime(df['TimeSnap'].apply(timesnap2date)).dt.dayofyear\n",
    "    df['DayOfWeek'] = pd.to_datetime(df['TimeSnap'].apply(timesnap2date)).dt.dayofweek\n",
    "    df['MonthOfYear'] = df['TimeSnap'].apply(lambda x : int(x[5:7]))\n",
    "    df['Morning'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) >=0 and int(x[11:13]) <12) else 0)\n",
    "    df['Afternoon'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) <18 and int(x[11:13]) >=12) else 0)\n",
    "    df['Evening'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) >= 18 and int(x[11:13]) < 24) else 0)\n",
    "    \n",
    "    # QuarterGameSecs, TotalGameSecsPlayed, HalfGameSecs\n",
    "    df['QuarterGameSecs'] = df['GameClock'].apply(gameclock2secs)\n",
    "    df['TotalGameSecsPlayed'] = (900 - df['QuarterGameSecs']) + ((df['Quarter'] - 1) * 900)\n",
    "    df['HalfGameSecsLeft'] = df['QuarterGameSecs']\n",
    "    df.loc[(df['Quarter'].isin([1,3])), 'HalfGameSecsLeft'] = (900 + df['QuarterGameSecs'])\n",
    "    \n",
    "    # IsInEngland\n",
    "    df['IsInEngland'] = df[\"Location\"].str.lower().map(lambda x: True if \"london\" in x else False)\n",
    "    \n",
    "    # StadiumType\n",
    "    # from https://www.kaggle.com/code1110/optimizing-lightgbm-hyperparameters\n",
    "    df['StadiumType'] = df['StadiumType'].apply(group_stadium_types)\n",
    "    \n",
    "    # Turf\n",
    "    # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\n",
    "    df['Turf'] = df['Turf'].map(Turf)\n",
    "    df['Turf'] = df['Turf'].map({\"Natural\": 0,\"Artificial\": 1})\n",
    "    \n",
    "    # GameWeather\n",
    "    # https://www.kaggle.com/code1110/optimizing-lightgbm-hyperparameters\n",
    "    #df['GameWeather'] = df['GameWeather'].apply(group_game_weather)\n",
    "    df['GameWeather'] = df['GameWeather'].str.lower()\n",
    "    indoor = \"indoor\"\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    df['GameWeather'] = df['GameWeather'].apply(map_weather)\n",
    "    \n",
    "        \n",
    "    # Temperature \n",
    "    df['Temperature'] = df['Temperature'].fillna(df['Temperature'].median())\n",
    "    \n",
    "    # Humidity\n",
    "    df['Humidity'] = df['Humidity'].fillna(df['Humidity'].median())\n",
    "    \n",
    "    # WindSpeed\n",
    "    #df['WindSpeed'] = df['WindSpeed'].apply(clean_wind_speed)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(str_to_float)\n",
    "    \n",
    "    # WindDirection\n",
    "    df['WindDirection'] = df['WindDirection'].apply(clean_WindDirection)    \n",
    "    df['WindDirection'] = df['WindDirection'].apply(transform_WindDirection)\n",
    "    \n",
    "    # Team\n",
    "    df['Team'] = df['Team'].map({\"home\": 0, \"away\": 1})\n",
    "    \n",
    "    # Dir\n",
    "    df[\"Dir\"] = np.mod(90 - df[\"Dir\"].values, 360)\n",
    "    \n",
    "    # PlayerBirthDate\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(birthday2day)\n",
    "    \n",
    "    # PlayerAge\n",
    "    df['PlayerAge'] = df['MatchDay'] - df['PlayerBirthDate']\n",
    "    \n",
    "    # PlayDirection\n",
    "    df['PlayDirection'] = df['PlayDirection'].apply(lambda x: x.strip() == 'right')\n",
    "    \n",
    "    # PlayerWeight\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(height2inch)\n",
    "    \n",
    "    # PlayerBMI\n",
    "    df['PlayerBMI'] = df['PlayerWeight'] / df['PlayerHeight']\n",
    "    \n",
    "    # DefendersInTheBox_vs_Distance\n",
    "    # from https://www.kaggle.com/ryches/model-free-benchmark\n",
    "    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n",
    "    \n",
    "    # Start\n",
    "    # from https://www.kaggle.com/sryo188558/cox-proportional-hazard-model\n",
    "    df[\"Start\"] = df[\"YardLine\"]\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == 1), \"Start\"] = df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == 1), \n",
    "                                                                                       \"YardLine\"] + 10\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == -1), \"Start\"] = 120 - df.loc[(df[\"OffenseInOwnTerritory\"] == 1) & (df[\"PlayDirection\"] == -1), \n",
    "                                                                                       \"YardLine\"] - 10\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == 1), \"Start\"] = 120 - df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == 1), \n",
    "                                                                                       \"YardLine\"] - 10\n",
    "    df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == -1), \"Start\"] = df.loc[(df[\"OffenseInOwnTerritory\"] == 0) & (df[\"PlayDirection\"] == -1), \n",
    "                                                                                       \"YardLine\"] + 10\n",
    "    # Orientation \n",
    "    df['Orientation'] = 2 * np.pi * (90 - df['Orientation']) / 360\n",
    "    \n",
    "    # locX\n",
    "    #df['locX'] = (df['X'].values - df['Start'].values) * df['PlayDirection'].values\n",
    "    #\n",
    "    ## locY\n",
    "    #df['locY'] = df['Y'].values - 53.3 / 2\n",
    "    #\n",
    "    ## velX\n",
    "    #df['velX'] = df['S'].values * np.cos(df['Orientation'].values) * df['PlayDirection'].values\n",
    "    #\n",
    "    ## velY\n",
    "    #df['velY'] = df['S'].values * np.sin(df['Orientation'].values)\n",
    "    #\n",
    "    ## accX\n",
    "    #df['accX'] = df['A'].values * np.cos(df['Orientation'].values) * df['PlayDirection'].values\n",
    "    #\n",
    "    ## accY\n",
    "    #df['accY'] = df['A'].values * np.sin(df['Orientation'].values)\n",
    "    \n",
    "    # HomeField\n",
    "    df['HomeField'] = df['FieldPosition'] == df['HomeTeamAbbr']\n",
    "    \n",
    "    # YardsLeft\n",
    "    df['YardsLeft'] = df.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n",
    "    df['YardsLeft'] = df.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)    \n",
    "    \n",
    "\n",
    "    df = df.drop(['NflId', 'NflIdRusher','TimeHandoff','TimeSnap','PlayerBirthDate',\n",
    "                 'Dir_rad','IsOnOffense','X_std','Y_std','Orientation_std','Dir_std'], axis=1)\n",
    "    \n",
    "    df = df.select_dtypes(exclude=['object'])\n",
    "    \n",
    "    #df.drop(df.index[(df['YardsLeft']<df['Yards']) | (df['YardsLeft']-100>df['Yards'])], inplace=True)\n",
    "    \n",
    "    df = df.sort_values(by=['PlayId', 'Team', 'IsRusher', 'JerseyNumber']).reset_index()\n",
    "    df.drop(['GameId', 'PlayId', 'index', 'IsRusher', 'Team'], axis=1, inplace=True)\n",
    "    \n",
    "    df.fillna(-999, inplace=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509762, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>Dis</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Dir</th>\n",
       "      <th>JerseyNumber</th>\n",
       "      <th>Season</th>\n",
       "      <th>YardLine</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Down</th>\n",
       "      <th>Distance</th>\n",
       "      <th>HomeScoreBeforePlay</th>\n",
       "      <th>VisitorScoreBeforePlay</th>\n",
       "      <th>OffenseFormation</th>\n",
       "      <th>DefendersInTheBox</th>\n",
       "      <th>PlayDirection</th>\n",
       "      <th>Yards</th>\n",
       "      <th>PlayerHeight</th>\n",
       "      <th>PlayerWeight</th>\n",
       "      <th>Week</th>\n",
       "      <th>StadiumType</th>\n",
       "      <th>Turf</th>\n",
       "      <th>GameWeather</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>ToLeft</th>\n",
       "      <th>YardLine_std</th>\n",
       "      <th>IsOffenseAtHome</th>\n",
       "      <th>OffenseScore</th>\n",
       "      <th>DefenseScore</th>\n",
       "      <th>IsOffenseWinning</th>\n",
       "      <th>OffenseInOwnTerritory</th>\n",
       "      <th>NumberOfBacksOnPlay</th>\n",
       "      <th>NumberOfOLinemenOnPlay</th>\n",
       "      <th>NumberOfWRsOnPlay</th>\n",
       "      <th>NumberOfTEsOnPlay</th>\n",
       "      <th>NumberOfDBsOnPlay</th>\n",
       "      <th>NumberOfDLinemenOnPlay</th>\n",
       "      <th>NumberOfLBsOnPlay</th>\n",
       "      <th>TimeBetweenSnapHandoff</th>\n",
       "      <th>MatchDay</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>MonthOfYear</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Afternoon</th>\n",
       "      <th>Evening</th>\n",
       "      <th>QuarterGameSecs</th>\n",
       "      <th>TotalGameSecsPlayed</th>\n",
       "      <th>HalfGameSecsLeft</th>\n",
       "      <th>IsInEngland</th>\n",
       "      <th>PlayerAge</th>\n",
       "      <th>PlayerBMI</th>\n",
       "      <th>DefendersInTheBox_vs_Distance</th>\n",
       "      <th>Start</th>\n",
       "      <th>HomeField</th>\n",
       "      <th>YardsLeft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.76</td>\n",
       "      <td>29.49</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.783377</td>\n",
       "      <td>339.14</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>736483</td>\n",
       "      <td>251</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>46</td>\n",
       "      <td>1754</td>\n",
       "      <td>False</td>\n",
       "      <td>14635</td>\n",
       "      <td>2.960526</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.70</td>\n",
       "      <td>19.19</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-1.084548</td>\n",
       "      <td>171.48</td>\n",
       "      <td>14</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>736483</td>\n",
       "      <td>251</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>46</td>\n",
       "      <td>1754</td>\n",
       "      <td>False</td>\n",
       "      <td>8743</td>\n",
       "      <td>2.614286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.47</td>\n",
       "      <td>36.91</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.384322</td>\n",
       "      <td>254.91</td>\n",
       "      <td>15</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>736483</td>\n",
       "      <td>251</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>46</td>\n",
       "      <td>1754</td>\n",
       "      <td>False</td>\n",
       "      <td>10904</td>\n",
       "      <td>2.876712</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.58</td>\n",
       "      <td>29.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-1.385093</td>\n",
       "      <td>207.95</td>\n",
       "      <td>60</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>736483</td>\n",
       "      <td>251</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>46</td>\n",
       "      <td>1754</td>\n",
       "      <td>False</td>\n",
       "      <td>9183</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.43</td>\n",
       "      <td>32.41</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.043431</td>\n",
       "      <td>227.24</td>\n",
       "      <td>61</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>736483</td>\n",
       "      <td>251</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>46</td>\n",
       "      <td>1754</td>\n",
       "      <td>False</td>\n",
       "      <td>10707</td>\n",
       "      <td>4.294872</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X      Y     S     A   Dis  Orientation     Dir  JerseyNumber  Season  \\\n",
       "0  79.76  29.49  0.84  1.22  0.00    -1.783377  339.14            12    2017   \n",
       "1  74.70  19.19  2.10  1.48  0.51    -1.084548  171.48            14    2017   \n",
       "2  76.47  36.91  5.15  0.77  0.59    -0.384322  254.91            15    2017   \n",
       "3  74.58  29.12  1.00  0.69  0.22    -1.385093  207.95            60    2017   \n",
       "4  75.43  32.41  1.50  1.36  0.32    -2.043431  227.24            61    2017   \n",
       "\n",
       "   YardLine  Quarter  Down  Distance  HomeScoreBeforePlay  \\\n",
       "0        35        1     3         2                    0   \n",
       "1        35        1     3         2                    0   \n",
       "2        35        1     3         2                    0   \n",
       "3        35        1     3         2                    0   \n",
       "4        35        1     3         2                    0   \n",
       "\n",
       "   VisitorScoreBeforePlay  OffenseFormation  DefendersInTheBox  PlayDirection  \\\n",
       "0                       0                 9                6.0          False   \n",
       "1                       0                 9                6.0          False   \n",
       "2                       0                 9                6.0          False   \n",
       "3                       0                 9                6.0          False   \n",
       "4                       0                 9                6.0          False   \n",
       "\n",
       "   Yards  PlayerHeight  PlayerWeight  Week  StadiumType  Turf  GameWeather  \\\n",
       "0      8            76           225     1            0     1          1.0   \n",
       "1      8            70           183     1            0     1          1.0   \n",
       "2      8            73           210     1            0     1          1.0   \n",
       "3      8            75           300     1            0     1          1.0   \n",
       "4      8            78           335     1            0     1          1.0   \n",
       "\n",
       "   Temperature  Humidity  WindSpeed  WindDirection  ToLeft  YardLine_std  \\\n",
       "0         63.0      77.0        8.0           1.25    True            35   \n",
       "1         63.0      77.0        8.0           1.25    True            35   \n",
       "2         63.0      77.0        8.0           1.25    True            35   \n",
       "3         63.0      77.0        8.0           1.25    True            35   \n",
       "4         63.0      77.0        8.0           1.25    True            35   \n",
       "\n",
       "   IsOffenseAtHome  OffenseScore  DefenseScore  IsOffenseWinning  \\\n",
       "0             True             0             0             False   \n",
       "1             True             0             0             False   \n",
       "2             True             0             0             False   \n",
       "3             True             0             0             False   \n",
       "4             True             0             0             False   \n",
       "\n",
       "   OffenseInOwnTerritory  NumberOfBacksOnPlay  NumberOfOLinemenOnPlay  \\\n",
       "0                   True                    2                       5   \n",
       "1                   True                    2                       5   \n",
       "2                   True                    2                       5   \n",
       "3                   True                    2                       5   \n",
       "4                   True                    2                       5   \n",
       "\n",
       "   NumberOfWRsOnPlay  NumberOfTEsOnPlay  NumberOfDBsOnPlay  \\\n",
       "0                  3                  1                  6   \n",
       "1                  3                  1                  6   \n",
       "2                  3                  1                  6   \n",
       "3                  3                  1                  6   \n",
       "4                  3                  1                  6   \n",
       "\n",
       "   NumberOfDLinemenOnPlay  NumberOfLBsOnPlay  TimeBetweenSnapHandoff  \\\n",
       "0                       4                  1                       1   \n",
       "1                       4                  1                       1   \n",
       "2                       4                  1                       1   \n",
       "3                       4                  1                       1   \n",
       "4                       4                  1                       1   \n",
       "\n",
       "   MatchDay  DayOfYear  DayOfWeek  MonthOfYear  Morning  Afternoon  Evening  \\\n",
       "0    736483        251          4            9        1          0        0   \n",
       "1    736483        251          4            9        1          0        0   \n",
       "2    736483        251          4            9        1          0        0   \n",
       "3    736483        251          4            9        1          0        0   \n",
       "4    736483        251          4            9        1          0        0   \n",
       "\n",
       "   QuarterGameSecs  TotalGameSecsPlayed  HalfGameSecsLeft  IsInEngland  \\\n",
       "0              854                   46              1754        False   \n",
       "1              854                   46              1754        False   \n",
       "2              854                   46              1754        False   \n",
       "3              854                   46              1754        False   \n",
       "4              854                   46              1754        False   \n",
       "\n",
       "   PlayerAge  PlayerBMI  DefendersInTheBox_vs_Distance  Start  HomeField  \\\n",
       "0      14635   2.960526                            3.0     35       True   \n",
       "1       8743   2.614286                            3.0     35       True   \n",
       "2      10904   2.876712                            3.0     35       True   \n",
       "3       9183   4.000000                            3.0     35       True   \n",
       "4      10707   4.294872                            3.0     35       True   \n",
       "\n",
       "   YardsLeft  \n",
       "0         35  \n",
       "1         35  \n",
       "2         35  \n",
       "3         35  \n",
       "4         35  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = preprocess(df)\n",
    "train_cols = train.columns\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cols that are not uniform in each play, append to players_col\n",
    "players_col = []\n",
    "for col in train.columns:\n",
    "    if train[col][:22].std()!=0:\n",
    "        players_col.append(col)\n",
    "\n",
    "X_train = train.drop('Yards', axis=1)\n",
    "X_train = np.array(X_train[players_col]).reshape(-1, len(players_col)*22)\n",
    "\n",
    "play_col = train.drop(players_col+['Yards'], axis=1).columns\n",
    "X_play_col = np.zeros(shape=(X_train.shape[0], len(play_col)))\n",
    "for i, col in enumerate(play_col):\n",
    "    X_play_col[:, i] = train[col][::22]\n",
    " \n",
    "X_train = np.concatenate([X_train, X_play_col], axis=1)\n",
    "y_train = np.zeros(shape=(X_train.shape[0], 199))\n",
    "for i,yard in enumerate(train['Yards'][::22]):\n",
    "    y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "players_col length & type:  12 <class 'list'>\n",
      "play_col shape & type:  (48,) <class 'pandas.core.indexes.base.Index'>\n",
      "X_play_col shape & type:  (23171, 48) <class 'numpy.ndarray'>\n",
      "X_train shape & type:  (23171, 312) <class 'numpy.ndarray'>\n",
      "y_train shape & type:  (23171, 199) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"players_col length & type: \", len(players_col), type(players_col))\n",
    "print(\"play_col shape & type: \", play_col.shape, type(play_col))\n",
    "print(\"X_play_col shape & type: \", X_play_col.shape, type(X_play_col))\n",
    "print(\"X_train shape & type: \", X_train.shape, type(X_train))\n",
    "print(\"y_train shape & type: \", y_train.shape, type(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/hukuda222/nfl-simple-model-using-lightgbm\n",
    "#train_data=np.zeros((509762//22, len(features)))\n",
    "#for i in tqdm.tqdm(range(0,509762,22)):\n",
    "#    count=0\n",
    "#    for c in features:\n",
    "#        train_data[i//22][count] = train_df[c][i]\n",
    "#        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_ = np.array([train_df[\"Yards\"][i] for i in range(0,509762,22)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = [f for f in features if f not in [\"Yards\"]]\n",
    "#X_train = X_train[features]\n",
    "#\n",
    "#print(X_train.shape)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np.zeros(len(y_train_), dtype=np.float)\n",
    "#for i in range(len(y_train)):\n",
    "#    y_train[i] = (y_train_[i])\n",
    "#\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#scaler.fit([[y] for y in y_train])\n",
    "#y_train = np.array([y[0] for y in scaler.transform([[y] for y in y_train])])\n",
    "#data = [0 for i in range(199)]\n",
    "#for y in y_train:\n",
    "#    data[int(y + 99)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "class RAdam(keras.optimizers.Optimizer):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    # Arguments\n",
    "        learning_rate: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        learning_rate = kwargs.pop('lr', learning_rate)\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n",
    "            decay_rate = (self.min_lr - lr) / decay_steps\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t))\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t))\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / (v_corr_t + self.epsilon), m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self.learning_rate\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'learning_rate': float(K.get_value(self.learning_rate)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.kaggle.com/davidcairuz/nfl-neural-network-w-softmax\n",
    "def crps(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - K.cumsum(y_pred, axis=1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    x = keras.layers.Input(shape=[X_train.shape[1]])\n",
    "    fc1 = keras.layers.Dense(units=450, input_shape=[X_train.shape[1]])(x)\n",
    "    act1 = keras.layers.PReLU()(fc1)\n",
    "    bn1 = keras.layers.BatchNormalization()(act1)\n",
    "    dp1 = keras.layers.Dropout(0.55)(bn1)\n",
    "    gn1 = keras.layers.GaussianNoise(0.15)(dp1)\n",
    "    concat1 = keras.layers.Concatenate()([x, gn1])\n",
    "    fc2 = keras.layers.Dense(units=600)(concat1)\n",
    "    act2 = keras.layers.PReLU()(fc2)\n",
    "    bn2 = keras.layers.BatchNormalization()(act2)\n",
    "    dp2 = keras.layers.Dropout(0.55)(bn2)\n",
    "    gn2 = keras.layers.GaussianNoise(0.15)(dp2)\n",
    "    concat2 = keras.layers.Concatenate()([concat1, gn2])\n",
    "    fc3 = keras.layers.Dense(units=400)(concat2)\n",
    "    act3 = keras.layers.PReLU()(fc3)\n",
    "    bn3 = keras.layers.BatchNormalization()(act3)\n",
    "    dp3 = keras.layers.Dropout(0.55)(bn3)\n",
    "    gn3 = keras.layers.GaussianNoise(0.15)(dp3)\n",
    "    concat3 = keras.layers.Concatenate([concat2, gn3])\n",
    "    output = keras.layers.Dense(units=199, activation='softmax')(concat2)\n",
    "    model = keras.models.Model(inputs=[x], outputs=[output])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    model = get_model()\n",
    "    model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7), loss=crps)\n",
    "    er = EarlyStopping(patience=20, min_delta=1e-4, restore_best_weights=True, monitor='val_loss')\n",
    "    model.fit(X_train, y_train, epochs=200, callbacks=[er], validation_data=[X_val, y_val], batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18536 samples, validate on 4635 samples\n",
      "Epoch 1/200\n",
      "18536/18536 [==============================] - 7s 390us/step - loss: 0.0964 - val_loss: 0.0874\n",
      "Epoch 2/200\n",
      "18536/18536 [==============================] - 6s 337us/step - loss: 0.0964 - val_loss: 0.0874\n",
      "Epoch 3/200\n",
      "18536/18536 [==============================] - 6s 337us/step - loss: 0.0961 - val_loss: 0.0874\n",
      "Epoch 4/200\n",
      "18536/18536 [==============================] - 6s 336us/step - loss: 0.0965 - val_loss: 0.0873\n",
      "Epoch 5/200\n",
      "18536/18536 [==============================] - 6s 337us/step - loss: 0.0964 - val_loss: 0.0874\n",
      "Epoch 6/200\n",
      "18536/18536 [==============================] - 6s 337us/step - loss: 0.0966 - val_loss: 0.0874\n",
      "Epoch 7/200\n",
      "18536/18536 [==============================] - 6s 336us/step - loss: 0.0969 - val_loss: 0.0874\n",
      "Epoch 8/200\n",
      "18536/18536 [==============================] - 7s 369us/step - loss: 0.0968 - val_loss: 0.0874\n",
      "Epoch 9/200\n",
      "18536/18536 [==============================] - 6s 339us/step - loss: 0.0965 - val_loss: 0.0875\n",
      "Epoch 10/200\n",
      "18536/18536 [==============================] - 6s 335us/step - loss: 0.0964 - val_loss: 0.0874\n",
      "Epoch 11/200\n",
      "18536/18536 [==============================] - 6s 338us/step - loss: 0.0967 - val_loss: 0.0873\n",
      "Epoch 12/200\n",
      "18536/18536 [==============================] - 6s 339us/step - loss: 0.0964 - val_loss: 0.0874\n",
      "Epoch 13/200\n",
      "18536/18536 [==============================] - 6s 349us/step - loss: 0.0965 - val_loss: 0.0874\n",
      "Epoch 14/200\n",
      "18536/18536 [==============================] - 7s 378us/step - loss: 0.0966 - val_loss: 0.0873\n",
      "Epoch 15/200\n",
      "18536/18536 [==============================] - 6s 344us/step - loss: 0.0967 - val_loss: 0.0874\n",
      "Epoch 16/200\n",
      "18536/18536 [==============================] - 6s 341us/step - loss: 0.0965 - val_loss: 0.0874\n",
      "Epoch 17/200\n",
      "18536/18536 [==============================] - 6s 338us/step - loss: 0.0964 - val_loss: 0.0874\n",
      "Epoch 18/200\n",
      "18536/18536 [==============================] - 6s 335us/step - loss: 0.0964 - val_loss: 0.0874\n",
      "Epoch 19/200\n",
      "18536/18536 [==============================] - 6s 338us/step - loss: 0.0971 - val_loss: 0.0874\n",
      "Epoch 20/200\n",
      "18536/18536 [==============================] - 6s 340us/step - loss: 0.0966 - val_loss: 0.0875\n",
      "Epoch 21/200\n",
      "18536/18536 [==============================] - 6s 340us/step - loss: 0.0969 - val_loss: 0.0874\n",
      "Train on 18537 samples, validate on 4634 samples\n",
      "Epoch 1/200\n",
      "18537/18537 [==============================] - 7s 378us/step - loss: 0.0958 - val_loss: 0.0878\n",
      "Epoch 2/200\n",
      "18537/18537 [==============================] - 6s 335us/step - loss: 0.0956 - val_loss: 0.0881\n",
      "Epoch 3/200\n",
      "18537/18537 [==============================] - 6s 336us/step - loss: 0.0956 - val_loss: 0.0881\n",
      "Epoch 4/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0950 - val_loss: 0.0880\n",
      "Epoch 5/200\n",
      "18537/18537 [==============================] - 6s 335us/step - loss: 0.0954 - val_loss: 0.0881\n",
      "Epoch 6/200\n",
      "18537/18537 [==============================] - 7s 354us/step - loss: 0.0953 - val_loss: 0.0881\n",
      "Epoch 7/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0951 - val_loss: 0.0881\n",
      "Epoch 8/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0952 - val_loss: 0.0881\n",
      "Epoch 9/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0954 - val_loss: 0.0881\n",
      "Epoch 10/200\n",
      "18537/18537 [==============================] - 6s 335us/step - loss: 0.0953 - val_loss: 0.0880\n",
      "Epoch 11/200\n",
      "18537/18537 [==============================] - 6s 349us/step - loss: 0.0954 - val_loss: 0.0881\n",
      "Epoch 12/200\n",
      "18537/18537 [==============================] - 7s 368us/step - loss: 0.0954 - val_loss: 0.0880\n",
      "Epoch 13/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0956 - val_loss: 0.0881\n",
      "Epoch 14/200\n",
      "18537/18537 [==============================] - 6s 346us/step - loss: 0.0953 - val_loss: 0.0881\n",
      "Epoch 15/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0951 - val_loss: 0.0881\n",
      "Epoch 16/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0955 - val_loss: 0.0881\n",
      "Epoch 17/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0956 - val_loss: 0.0881\n",
      "Epoch 18/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0956 - val_loss: 0.0880\n",
      "Epoch 19/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0953 - val_loss: 0.0880\n",
      "Epoch 20/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0954 - val_loss: 0.0880\n",
      "Epoch 21/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0951 - val_loss: 0.0880\n",
      "Train on 18537 samples, validate on 4634 samples\n",
      "Epoch 1/200\n",
      "18537/18537 [==============================] - 7s 376us/step - loss: 0.0937 - val_loss: 0.0867\n",
      "Epoch 2/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0939 - val_loss: 0.0869\n",
      "Epoch 3/200\n",
      "18537/18537 [==============================] - 6s 335us/step - loss: 0.0940 - val_loss: 0.0869\n",
      "Epoch 4/200\n",
      "18537/18537 [==============================] - 7s 368us/step - loss: 0.0938 - val_loss: 0.0869\n",
      "Epoch 5/200\n",
      "18537/18537 [==============================] - 6s 348us/step - loss: 0.0939 - val_loss: 0.0868\n",
      "Epoch 6/200\n",
      "18537/18537 [==============================] - 6s 335us/step - loss: 0.0939 - val_loss: 0.0868\n",
      "Epoch 7/200\n",
      "18537/18537 [==============================] - 6s 336us/step - loss: 0.0941 - val_loss: 0.0868\n",
      "Epoch 8/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0939 - val_loss: 0.0869\n",
      "Epoch 9/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0939 - val_loss: 0.0869\n",
      "Epoch 10/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0937 - val_loss: 0.0869\n",
      "Epoch 11/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0936 - val_loss: 0.0869\n",
      "Epoch 12/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0939 - val_loss: 0.0869\n",
      "Epoch 13/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0938 - val_loss: 0.0868\n",
      "Epoch 14/200\n",
      "18537/18537 [==============================] - 6s 344us/step - loss: 0.0940 - val_loss: 0.0869\n",
      "Epoch 15/200\n",
      "18537/18537 [==============================] - 6s 346us/step - loss: 0.0935 - val_loss: 0.0869\n",
      "Epoch 16/200\n",
      "18537/18537 [==============================] - 6s 346us/step - loss: 0.0941 - val_loss: 0.0870\n",
      "Epoch 17/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0940 - val_loss: 0.0869\n",
      "Epoch 18/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0938 - val_loss: 0.0869\n",
      "Epoch 19/200\n",
      "18537/18537 [==============================] - 6s 344us/step - loss: 0.0943 - val_loss: 0.0867\n",
      "Epoch 7/200\n",
      "18537/18537 [==============================] - 6s 347us/step - loss: 0.0946 - val_loss: 0.0868\n",
      "Epoch 8/200\n",
      "18537/18537 [==============================] - 7s 368us/step - loss: 0.0944 - val_loss: 0.0868\n",
      "Epoch 9/200\n",
      "18537/18537 [==============================] - 7s 352us/step - loss: 0.0947 - val_loss: 0.0867\n",
      "Epoch 10/200\n",
      "18537/18537 [==============================] - 7s 377us/step - loss: 0.0948 - val_loss: 0.0867\n",
      "Epoch 11/200\n",
      "18537/18537 [==============================] - 7s 364us/step - loss: 0.0947 - val_loss: 0.0867\n",
      "Epoch 12/200\n",
      "18537/18537 [==============================] - 6s 350us/step - loss: 0.0947 - val_loss: 0.0868\n",
      "Epoch 13/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0944 - val_loss: 0.0867\n",
      "Epoch 14/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0946 - val_loss: 0.0868\n",
      "Epoch 15/200\n",
      "18537/18537 [==============================] - 7s 360us/step - loss: 0.0944 - val_loss: 0.0867\n",
      "Epoch 16/200\n",
      "18537/18537 [==============================] - 8s 413us/step - loss: 0.0941 - val_loss: 0.0868\n",
      "Epoch 17/200\n",
      "18537/18537 [==============================] - 7s 359us/step - loss: 0.0943 - val_loss: 0.0867\n",
      "Epoch 18/200\n",
      "18537/18537 [==============================] - 7s 354us/step - loss: 0.0944 - val_loss: 0.0868\n",
      "Epoch 19/200\n",
      "18537/18537 [==============================] - 7s 351us/step - loss: 0.0946 - val_loss: 0.0867\n",
      "Epoch 20/200\n",
      "18537/18537 [==============================] - 7s 359us/step - loss: 0.0946 - val_loss: 0.0868\n",
      "Epoch 21/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0945 - val_loss: 0.0868\n",
      "Train on 18537 samples, validate on 4634 samples\n",
      "Epoch 1/200\n",
      "18537/18537 [==============================] - 8s 417us/step - loss: 0.0941 - val_loss: 0.0846\n",
      "Epoch 2/200\n",
      "18537/18537 [==============================] - 7s 370us/step - loss: 0.0941 - val_loss: 0.0846\n",
      "Epoch 3/200\n",
      "18537/18537 [==============================] - 7s 364us/step - loss: 0.0940 - val_loss: 0.0845\n",
      "Epoch 4/200\n",
      "18537/18537 [==============================] - 7s 358us/step - loss: 0.0942 - val_loss: 0.0846\n",
      "Epoch 5/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0943 - val_loss: 0.0846\n",
      "Epoch 6/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0944 - val_loss: 0.0846\n",
      "Epoch 7/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0943 - val_loss: 0.0846\n",
      "Epoch 8/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0945 - val_loss: 0.0846\n",
      "Epoch 9/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0940 - val_loss: 0.0846\n",
      "Epoch 10/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0943 - val_loss: 0.0846\n",
      "Epoch 11/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0941 - val_loss: 0.0846\n",
      "Epoch 12/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0939 - val_loss: 0.0846\n",
      "Epoch 13/200\n",
      "18537/18537 [==============================] - 6s 335us/step - loss: 0.0940 - val_loss: 0.0845\n",
      "Epoch 14/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0941 - val_loss: 0.0846\n",
      "Epoch 15/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0942 - val_loss: 0.0846\n",
      "Epoch 16/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0938 - val_loss: 0.0845\n",
      "Epoch 17/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0941 - val_loss: 0.0845\n",
      "Epoch 18/200\n",
      "18537/18537 [==============================] - 6s 336us/step - loss: 0.0941 - val_loss: 0.0847\n",
      "Epoch 19/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0942 - val_loss: 0.0846\n",
      "Epoch 20/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0938 - val_loss: 0.0845\n",
      "Epoch 21/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0939 - val_loss: 0.0846\n",
      "Train on 18536 samples, validate on 4635 samples\n",
      "Epoch 1/200\n",
      "18536/18536 [==============================] - 7s 401us/step - loss: 0.0944 - val_loss: 0.0867\n",
      "Epoch 2/200\n",
      "18536/18536 [==============================] - 7s 380us/step - loss: 0.0951 - val_loss: 0.0870\n",
      "Epoch 3/200\n",
      "18536/18536 [==============================] - 6s 344us/step - loss: 0.0945 - val_loss: 0.0869\n",
      "Epoch 4/200\n",
      "18536/18536 [==============================] - 6s 346us/step - loss: 0.0948 - val_loss: 0.0869\n",
      "Epoch 5/200\n",
      "18536/18536 [==============================] - 6s 343us/step - loss: 0.0944 - val_loss: 0.0869\n",
      "Epoch 6/200\n",
      "18536/18536 [==============================] - 6s 343us/step - loss: 0.0947 - val_loss: 0.0869\n",
      "Epoch 7/200\n",
      "18536/18536 [==============================] - 6s 343us/step - loss: 0.0946 - val_loss: 0.0869\n",
      "Epoch 8/200\n",
      "18536/18536 [==============================] - 6s 342us/step - loss: 0.0946 - val_loss: 0.0869\n",
      "Epoch 9/200\n",
      "18536/18536 [==============================] - 6s 344us/step - loss: 0.0949 - val_loss: 0.0870\n",
      "Epoch 10/200\n",
      "18536/18536 [==============================] - 6s 342us/step - loss: 0.0949 - val_loss: 0.0870\n",
      "Epoch 11/200\n",
      "18536/18536 [==============================] - 6s 340us/step - loss: 0.0947 - val_loss: 0.0869\n",
      "Epoch 12/200\n",
      "18536/18536 [==============================] - 6s 342us/step - loss: 0.0946 - val_loss: 0.0869\n",
      "Epoch 13/200\n",
      "18536/18536 [==============================] - 7s 364us/step - loss: 0.0944 - val_loss: 0.0870\n",
      "Epoch 14/200\n",
      "18536/18536 [==============================] - 6s 346us/step - loss: 0.0942 - val_loss: 0.0869\n",
      "Epoch 15/200\n",
      "18536/18536 [==============================] - 6s 339us/step - loss: 0.0946 - val_loss: 0.0870\n",
      "Epoch 16/200\n",
      "18536/18536 [==============================] - 6s 339us/step - loss: 0.0948 - val_loss: 0.0870\n",
      "Epoch 17/200\n",
      "18536/18536 [==============================] - 6s 339us/step - loss: 0.0947 - val_loss: 0.0869\n",
      "Epoch 18/200\n",
      "18536/18536 [==============================] - 6s 339us/step - loss: 0.0950 - val_loss: 0.0869\n",
      "Epoch 19/200\n",
      "18536/18536 [==============================] - 7s 352us/step - loss: 0.0949 - val_loss: 0.0869\n",
      "Epoch 20/200\n",
      "18536/18536 [==============================] - 7s 370us/step - loss: 0.0946 - val_loss: 0.0869\n",
      "Epoch 21/200\n",
      "18536/18536 [==============================] - 6s 341us/step - loss: 0.0946 - val_loss: 0.0870\n",
      "Train on 18537 samples, validate on 4634 samples\n",
      "Epoch 1/200\n",
      "18537/18537 [==============================] - 7s 387us/step - loss: 0.0957 - val_loss: 0.0891\n",
      "Epoch 2/200\n",
      "18537/18537 [==============================] - 6s 349us/step - loss: 0.0956 - val_loss: 0.0895\n",
      "Epoch 3/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0954 - val_loss: 0.0895\n",
      "Epoch 4/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0957 - val_loss: 0.0896\n",
      "Epoch 5/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0956 - val_loss: 0.0896\n",
      "Epoch 6/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0957 - val_loss: 0.0896\n",
      "Epoch 7/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0958 - val_loss: 0.0896\n",
      "Epoch 8/200\n",
      "18537/18537 [==============================] - 6s 343us/step - loss: 0.0952 - val_loss: 0.0895\n",
      "Epoch 9/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0956 - val_loss: 0.0895\n",
      "Epoch 10/200\n",
      "18537/18537 [==============================] - 6s 337us/step - loss: 0.0956 - val_loss: 0.0896\n",
      "Epoch 11/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0954 - val_loss: 0.0896\n",
      "Epoch 12/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0955 - val_loss: 0.0896\n",
      "Epoch 13/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0955 - val_loss: 0.0896\n",
      "Epoch 14/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0954 - val_loss: 0.0896\n",
      "Epoch 15/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0956 - val_loss: 0.0895\n",
      "Epoch 16/200\n",
      "18537/18537 [==============================] - 6s 339us/step - loss: 0.0953 - val_loss: 0.0895\n",
      "Epoch 17/200\n",
      "18537/18537 [==============================] - 6s 343us/step - loss: 0.0954 - val_loss: 0.0895\n",
      "Epoch 18/200\n",
      "18537/18537 [==============================] - 6s 338us/step - loss: 0.0953 - val_loss: 0.0895\n",
      "Epoch 19/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0958 - val_loss: 0.0895\n",
      "Epoch 20/200\n",
      "18537/18537 [==============================] - 6s 345us/step - loss: 0.0953 - val_loss: 0.0896\n",
      "Epoch 21/200\n",
      "18537/18537 [==============================] - 6s 341us/step - loss: 0.0958 - val_loss: 0.0895\n",
      "Train on 18537 samples, validate on 4634 samples\n",
      "Epoch 1/200\n",
      "18537/18537 [==============================] - 7s 390us/step - loss: 0.0951 - val_loss: 0.0862\n",
      "Epoch 2/200\n",
      "18537/18537 [==============================] - 6s 343us/step - loss: 0.0952 - val_loss: 0.0866\n",
      "Epoch 3/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0947 - val_loss: 0.0873\n",
      "Epoch 5/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0951 - val_loss: 0.0873\n",
      "Epoch 6/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0947 - val_loss: 0.0873\n",
      "Epoch 7/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0948 - val_loss: 0.0872\n",
      "Epoch 8/200\n",
      "18537/18537 [==============================] - 6s 340us/step - loss: 0.0947 - val_loss: 0.0872\n",
      "Epoch 9/200\n",
      "18536/18536 [==============================] - 6s 336us/step - loss: 0.0961 - val_loss: 0.0875\n",
      "Epoch 15/200\n",
      "18536/18536 [==============================] - 7s 373us/step - loss: 0.0965 - val_loss: 0.0874\n",
      "Epoch 16/200\n",
      "18536/18536 [==============================] - 6s 342us/step - loss: 0.0965 - val_loss: 0.0875\n",
      "Epoch 17/200\n",
      "18536/18536 [==============================] - 6s 343us/step - loss: 0.0964 - val_loss: 0.0875\n",
      "Epoch 18/200\n",
      "18536/18536 [==============================] - 6s 338us/step - loss: 0.0965 - val_loss: 0.0875\n",
      "Epoch 19/200\n",
      "12544/18536 [===================>..........] - ETA: 1s - loss: 0.0970Train on 18537 samples, validate on 4634 samples\n",
      "Epoch 1/200\n",
      "18537/18537 [==============================] - 7s 386us/step - loss: 0.0960 - val_loss: 0.0871\n",
      "Epoch 2/200\n",
      "18537/18537 [==============================] - 6s 342us/step - loss: 0.0961 - val_loss: 0.0873\n",
      "Epoch 3/200\n",
      "18537/18537 [==============================] - 6s 344us/step - loss: 0.0961 - val_loss: 0.0874\n",
      "Epoch 4/200\n",
      "18537/18537 [==============================] - 6s 343us/step - loss: 0.0962 - val_loss: 0.0873\n",
      "Epoch 5/200\n",
      "18537/18537 [==============================] - 6s 343us/step - loss: 0.0960 - val_loss: 0.0874\n",
      "Epoch 6/200\n",
      " 1600/18537 [=>............................] - ETA: 5s - loss: 0.0945"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "models = []\n",
    "\n",
    "for tr_idx, vl_idx in rkf.split(X_train, y_train):\n",
    "    \n",
    "    x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n",
    "    x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n",
    "    \n",
    "    model = train_model(x_tr, y_tr, x_vl, y_vl)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(df, sample, env, models):\n",
    "    #print('#### BEGINNING #### ')\n",
    "    #print('Raw df shape: ', df.shape)\n",
    "    #print('Running df preprocessing...')\n",
    "    df = preprocess(df)\n",
    "    #df_cols = df.columns\n",
    "\n",
    "    #print('df preprocessing complete')\n",
    "    #print('df shape: ', df.shape)\n",
    "    #print(' ')\n",
    "    \n",
    "    #print('Difference between train and df cols')\n",
    "    #col_diff = list(set(train_cols) - set(df_cols))\n",
    "    #print(col_diff)\n",
    "    #print(' ')\n",
    "    \n",
    "    #print('Reshaping X and removing players_col...')\n",
    "    X = np.array(df[players_col]).reshape(-1, len(players_col)*22)\n",
    "    #print('Reshape complete')\n",
    "    #print('X shape: ', X.shape)\n",
    "    #print(' ')\n",
    "\n",
    "    \n",
    "    #print('Defining play_col...')\n",
    "    play_col = df.drop(players_col, axis=1).columns\n",
    "    #print('play_col shape: ', play_col.shape)\n",
    "    #print(' ')\n",
    "    \n",
    "    \n",
    "    #print('Defining X_play_col...')\n",
    "    X_play_col = np.zeros(shape=(X.shape[0], len(play_col)))\n",
    "    #print('X_play_col shape(1): ', X_play_col.shape)\n",
    "    #print(' ')\n",
    "\n",
    "    \n",
    "    #print('Selecting X_play_col data...')\n",
    "    for i, col in enumerate(play_col):\n",
    "        X_play_col[:, i] = df[col][::22]\n",
    "    #print('X_play_col shape(2): ', X_play_col.shape)\n",
    "    #print(' ')\n",
    "    \n",
    "    \n",
    "    #print('Concatenating X with X_play_col...')\n",
    "    X = np.concatenate([X, X_play_col], axis=1)\n",
    "    #print('X concatenation complete')\n",
    "    #print('X shape: ', X.shape)\n",
    "    #print(' ')\n",
    "\n",
    "    \n",
    "    #print('Scaling X...')\n",
    "    X = scaler.transform(X)\n",
    "    #print('Scaling X complete')\n",
    "    #print('X shape: ', X.shape)\n",
    "    #print(' ')\n",
    "\n",
    "    \n",
    "    #print('Predicting y_pred...')    \n",
    "    y_pred = np.mean([np.cumsum(model.predict(X), axis=1) for model in models], axis=0)\n",
    "    #print('Prediction complete')\n",
    "    #print('y_pred shape: ', y_pred.shape)\n",
    "    #print(' ')\n",
    "\n",
    "    \n",
    "    #print('Defining YardsLeft...')\n",
    "    yardsleft = np.array(df['YardsLeft'][::22])\n",
    "    #print('YardsLeft shape: ', yardsleft.shape)\n",
    "    #print(' ')\n",
    "\n",
    "    \n",
    "    #print('Looping y_pred for final sub...')\n",
    "    for i in range(len(yardsleft)):\n",
    "        y_pred[i, :yardsleft[i]-1] = 0\n",
    "        y_pred[i, yardsleft[i]+100:] = 1\n",
    "    #print('y_pred loop complete')\n",
    "    #print('y_pred shape: ', y_pred.shape)\n",
    "    #print(' ')\n",
    "\n",
    "    \n",
    "    #print('Finalising submission')\n",
    "    env.predict(pd.DataFrame(data=y_pred.clip(0,1),columns=sample.columns))\n",
    "    #print('Submission complete. Moving to next iteration.')\n",
    "    #print('#### END ####')\n",
    "    #print(' ')\n",
    "    #print(' ')\n",
    "    #print(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3438it [18:34,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()\n",
    "\n",
    "for test, sample in tqdm.tqdm(env.iter_test()):\n",
    "    make_pred(test, sample, env, models)\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from https://www.kaggle.com/newbielch/lgbm-regression-view\n",
    "#def get_cdf_df(yards_array):\n",
    "#    pdf, edges = np.histogram(yards_array, bins=199,\n",
    "#                 range=(-99,100), density=True)\n",
    "#    cdf = pdf.cumsum().clip(0, 1)\n",
    "#    cdf_df = pd.DataFrame(data=cdf.reshape(-1, 1).T, \n",
    "#                            columns=['Yards'+str(i) for i in range(-99,100)])\n",
    "#    return cdf_df\n",
    "#cdf = get_cdf_df(y_train).values.reshape(-1,)\n",
    "##dist_to_end_train = X_train.apply(lambda x:(100 - x.loc['YardLine']) if x.loc[\"OffenseInOwnTerritory\"]==1 else x.loc['YardLine'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_score(y_pred,cdf,w,dist_to_end):\n",
    "#    y_pred = int(y_pred)\n",
    "##     y_pred = y_pred.astype(int)\n",
    "#    if y_pred ==w:\n",
    "#        y_pred_array = cdf.copy()\n",
    "#    elif y_pred - w >0:\n",
    "#        y_pred_array = np.zeros(199)\n",
    "#        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "#    elif w - y_pred >0:\n",
    "#        y_pred_array = np.ones(199)\n",
    "#        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "#    y_pred_array[-1]=1\n",
    "#    y_pred_array[(dist_to_end+99):]=1\n",
    "#    return y_pred_array    \n",
    "#\n",
    "#def get_score_pingyi1(y_pred,y_true,cdf,w,dist_to_end):\n",
    "#    y_pred = int(y_pred)\n",
    "#    if y_pred ==w:\n",
    "#        y_pred_array = cdf.copy()\n",
    "#    elif y_pred - w >0:\n",
    "#        y_pred_array = np.zeros(199)\n",
    "#        y_pred_array[(y_pred-w):] = cdf[:(-(y_pred-w))].copy()\n",
    "#    elif w - y_pred >0:\n",
    "#        y_pred_array = np.ones(199)\n",
    "#        y_pred_array[:(y_pred-w)] = cdf[(w-y_pred):].copy()\n",
    "#    y_pred_array[-1]=1\n",
    "#    y_pred_array[(dist_to_end+99):]=1\n",
    "#    y_true_array = np.zeros(199)\n",
    "#    y_true_array[(y_true+99):]=1\n",
    "#    return np.mean((y_pred_array - y_true_array)**2)\n",
    "#\n",
    "#\n",
    "#def CRPS_pingyi1(y_preds,y_trues,w,cdf,dist_to_ends):\n",
    "#    if len(y_preds) != len(y_trues):\n",
    "#        print('length does not match')\n",
    "#        return None\n",
    "#    n = len(y_preds)\n",
    "#    tmp = []\n",
    "#    for a,b,c in zip(y_preds, y_trues, dist_to_ends):\n",
    "#        tmp.append(get_score_pingyi1(a,b,cdf,w,c))\n",
    "#    return np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial LGB parameters are ...\n",
    "#lgbParams = {\n",
    "#    'objective': 'regression',\n",
    "#    'metric': 'mae',\n",
    "#    'verbosity': -1,\n",
    "#    'boosting_type': 'gbdt',\n",
    "#    \"num_iterations\": 1000, \n",
    "#    \"learning_rate\": 0.05,\n",
    "#    \"lambda_l1\": 9,\n",
    "#    \"lambda_l2\": 0.9,\n",
    "#    \"num_leaves\": 42,\n",
    "#    \"feature_fraction\": 0.4,\n",
    "#    \"bagging_fraction\": 0.45,\n",
    "#    \"bagging_freq\": 7,\n",
    "#    \"min_child_samples\": 74,\n",
    "#    \"random_state\": 14\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize feature importance\n",
    "#\n",
    "## make a LightGBM dataset\n",
    "#trainX, testX, trainY, testY = train_test_split(X_train, y_train, test_size=0.33, random_state=14)\n",
    "#d_train = lgb.Dataset(trainX, trainY)\n",
    "#d_eval = lgb.Dataset(testX, testY, reference=d_train)\n",
    "#\n",
    "## model training\n",
    "#LGBmodel = lgb.train(lgbParams, d_train, valid_sets=d_eval, verbose_eval=1000)\n",
    "## LGBmodel = lgb.train(lgbParams, d_train, valid_sets=d_eval, early_stopping_rounds=500, verbose_eval=1000)\n",
    "#\n",
    "## feature importance\n",
    "#importance = LGBmodel.feature_importance(importance_type=\"gain\")\n",
    "#ranking = np.argsort(-importance)\n",
    "#fig, ax = plt.subplots(figsize=(20, 20))\n",
    "#sns.barplot(x=importance[ranking], y=X_train.columns.values[ranking], orient='h')\n",
    "#ax.set_xlabel(\"feature importance\")\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = X_train.columns.values[ranking][:30]\n",
    "#print(features)\n",
    "#X_train = X_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FYI: Objective functions can take additional arguments\n",
    "## (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "#def objective(trial):\n",
    "#  \n",
    "#    # make a LightGBM dataset\n",
    "#    trainX, testX, trainY, testY = train_test_split(X_train, y_train, test_size=0.33, random_state=14)\n",
    "#    d_train = lgb.Dataset(trainX, trainY)\n",
    "#\n",
    "#    param = {\n",
    "#        'objective': 'regression',\n",
    "#        'metric': 'mae',\n",
    "#        'verbosity': -1,\n",
    "#        'boosting_type': 'gbdt',\n",
    "#        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "#        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "#        'num_leaves': trial.suggest_int('num_leaves', 40, 256),\n",
    "#        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "#        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "#        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "#        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "#    }\n",
    "#\n",
    "#    gbm = lgb.train(param, d_train)\n",
    "#    preds = gbm.predict(testX)\n",
    "#    mae = mean_absolute_error(testY, preds)\n",
    "#    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#study = optuna.create_study(direction='minimize')\n",
    "#study.optimize(objective, n_trials=100)\n",
    "#\n",
    "#print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "#\n",
    "#print('Best trial:')\n",
    "#trial = study.best_trial\n",
    "#\n",
    "#print('  Value: {}'.format(trial.value))\n",
    "#\n",
    "#print('  Params: ')\n",
    "#for key, value in trial.params.items():\n",
    "#    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbParams = trial.params\n",
    "#lgbParams['objective'] = 'regression'\n",
    "#lgbParams['metric'] = 'mae'\n",
    "#lgbParams['verbosity'] = -1\n",
    "#lgbParams['boosting_type'] = 'gbdt'\n",
    "#lgbParams[\"learning_rate\"] = 0.01\n",
    "#lgbParams[\"num_iterations\"] = 5000\n",
    "#lgbParams[\"random_state\"] = 14\n",
    "#print(lgbParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbParams = {'lambda_l1': 9.830445878717612, \n",
    "#             'lambda_l2': 9.889595129567367, \n",
    "#             'num_leaves': 41, \n",
    "#             'feature_fraction': 0.4152661948258711,\n",
    "#             'bagging_fraction': 0.9170414824158851, \n",
    "#             'bagging_freq': 7, \n",
    "#             'min_child_samples': 44, \n",
    "#             'objective': 'regression', \n",
    "#             'metric': 'mae', \n",
    "#             'verbosity': -1, \n",
    "#             'boosting_type': 'gbdt', \n",
    "#             'learning_rate': 0.01, \n",
    "#             'num_iterations': 5000, \n",
    "#             'random_state': 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_splits = 5\n",
    "#seed = 14\n",
    "#kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "#y_valid = np.zeros(X_train.shape[0])\n",
    "#models = []\n",
    "#\n",
    "#for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "#    trainX, trainY = X_train.iloc[train_idx, :], y_train[train_idx]\n",
    "#    validX, validY = X_train.iloc[valid_idx, :], y_train[valid_idx]\n",
    "#    \n",
    "#    d_train = lgb.Dataset(trainX, trainY)\n",
    "#    d_eval = lgb.Dataset(validX, validY, reference=d_train)\n",
    "#    \n",
    "#    LGBmodel = lgb.train(lgbParams, d_train, valid_sets=d_eval, \n",
    "#                         early_stopping_rounds=500, \n",
    "#                         learning_rates = lambda iter: 0.01 * (0.99 ** iter),\n",
    "#                         verbose_eval = 1000)\n",
    "#    y_valid[valid_idx] += LGBmodel.predict(validX, num_iteration=LGBmodel.best_iteration)\n",
    "#    models.append(LGBmodel)\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cprs = CRPS_pingyi1(y_valid, y_train.astype(int), 4, cdf, dist_to_end_train.astype(int))\n",
    "#print(\"cprs = {}\".format(cprs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from kaggle.competitions import nflrush\n",
    "#env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index = 0\n",
    "#for (test_df, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n",
    "#    test = preprocess(test_df)\n",
    "#    \n",
    "#    count=0\n",
    "#    test_data = np.zeros((1,len(features)))\n",
    "#    for c in features:\n",
    "#        try:\n",
    "#            test_data[0][count] = test[c][index]\n",
    "#        except:\n",
    "#            test_data[0][count] = np.nan\n",
    "#        count+=1\n",
    "#    \n",
    "#    y_pred = np.zeros(199)    \n",
    "#    y_pred_p = np.sum(np.round(scaler.inverse_transform(\n",
    "#        [model.predict(test_data) for model in models]))) / n_splits\n",
    "#    \n",
    "#    y_pred_p += 99\n",
    "#    for j in range(199):\n",
    "#        if j>=y_pred_p+10:\n",
    "#            y_pred[j]=1.0\n",
    "#        elif j>=y_pred_p-10:\n",
    "#            y_pred[j]=(j+10-y_pred_p)*0.05\n",
    "#\n",
    "#    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n",
    "#    index += 22\n",
    "#env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
